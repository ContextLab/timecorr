{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cefa7252a7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../timecorr/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/timecorr/timecorr/_shared/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window_isfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimecorr_smoothing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window_smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "######## timecorr vs sliding window, different variances & ramp correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from math import log\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "variance = [10,50,100,500]\n",
    "sliding_window_length = [5,11,25,51]\n",
    "repetitions=100\n",
    "var_num = len(variance)\n",
    "slide_num = len(sliding_window_length)\n",
    "\n",
    "block_length = 1\n",
    "covariance_num =  100\n",
    "time_len = int(block_length * covariance_num)\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_ramp_correlation_data():\n",
    "    global activations, correlations,correlation1,correlation2\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "    correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "    \n",
    "    while not is_pos_def(correlation1):\n",
    "        feature_map = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation1 = 2*np.dot(feature_map,feature_map.T)-1\n",
    "        correlation1 = correlation1/np.max(abs(correlation1))\n",
    "        \n",
    "    while not is_pos_def(correlation2):\n",
    "        feature_map1 = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation2 = 2*np.dot(feature_map1,feature_map1.T)-1\n",
    "        correlation2 = correlation2/np.max(abs(correlation2))\n",
    "        \n",
    "    for i in range(time_len):\n",
    "        cov_temp = (time_len-i)*0.5*(np.log(1+correlation1+1e-5) - np.log(1-correlation1+1e-5))/float(time_len)+i*0.5*(np.log(1+correlation2+1e-5) - np.log(1-correlation2+1e-5))/float(time_len)\n",
    "        correlations[i] =  (np.exp(2*cov_temp) - 1)/(np.exp(2*cov_temp) + 1)\n",
    "        activations[:,i] = np.dot(cholesky(correlations[i]),activations[:,i])\n",
    "#     correlations[0]=correlation1\n",
    "#     correlations[1]=correlation2\n",
    "#     activations[:,:block_length]=np.dot(cholesky(correlation1),activations[:,:block_length])\n",
    "#     activations[:,block_length:]=np.dot(cholesky(correlation2),activations[:,block_length:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timecorr_correlations1,timecorr_correlations2 = np.zeros([repetitions,var_num,time_len]),np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations1,sliding_window_correlations2 = np.zeros([repetitions,slide_num,time_len]),np.zeros([repetitions,slide_num,time_len])\n",
    "true_correlations1,true_correlations2 = np.zeros([time_len]),np.zeros([time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations_single = np.zeros([repetitions,slide_num,time_len])\n",
    "\n",
    "color = ['b','r','k']\n",
    "\n",
    "#timecorr_recovery = np.zeros([var_num,time_len,(activation_num * (activation_num-1) / 2)])\n",
    "#sliding_window_recovery = np.zeros([slide_num, time_len,(activation_num * (activation_num-1) / 2)])\n",
    "#true_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\n",
    "\n",
    "timecorr_recovery = np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "sliding_window_recovery = np.zeros([slide_num, time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "true_recovery = np.zeros([time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "\n",
    "for i in range(repetitions):\n",
    "    cholesky_ramp_correlation_data()\n",
    "    for v in range(var_num):\n",
    "        timecorr_recovery[v] = wcorr(activations,variance[v])\n",
    "        sliding_window_recovery[v,int(sliding_window_length[v]/2):(time_len-int(sliding_window_length[v]/2))] = sliding_window(activations,sliding_window_length[v]) \n",
    "        \n",
    "    for t in range(time_len):\n",
    "        true_recovery[t] = squareform(correlations[int(t/block_length)],checks=False)\n",
    "    for timepoint in range(time_len):\n",
    "        for v in range(var_num):\n",
    "            otc1 = pearsonr(timecorr_recovery[v,timepoint], squareform(correlation1,checks=False))[0]\n",
    "            timecorr_correlations1[i,v,timepoint] += 0.5 * (log(1+otc1) - log(1-otc1))\n",
    "            otc2 = pearsonr(timecorr_recovery[v,timepoint], squareform(correlation2,checks=False))[0]\n",
    "            timecorr_correlations2[i,v,timepoint] += 0.5 * (log(1+otc2) - log(1-otc2))\n",
    "            \n",
    "            otcs = pearsonr(timecorr_recovery[v, timepoint], true_recovery[timepoint])[0]\n",
    "#             otcs = pearsonr(timecorr_recovery[v, timepoint], squareform(correlations[timepoint/block_length],checks=False))[0]\n",
    "            timecorr_correlations_single[i,v, timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "        \n",
    "            if timepoint>int(sliding_window_length[v]/2)-1 and timepoint<time_len-int(sliding_window_length[v]/2):\n",
    "                sc1 = pearsonr(sliding_window_recovery[v,timepoint], squareform(correlation1,checks=False))[0]\n",
    "                sliding_window_correlations1[i,v,timepoint] += 0.5 * (log(1+sc1) - log(1-sc1))\n",
    "                sc2 = pearsonr(sliding_window_recovery[v,timepoint], squareform(correlation2,checks=False))[0]\n",
    "                sliding_window_correlations2[i,v,timepoint] += 0.5 * (log(1+sc2) - log(1-sc2))\n",
    "                swc = pearsonr(sliding_window_recovery[v,timepoint], true_recovery[timepoint])[0]\n",
    "#                 swc = pearsonr(sliding_window_recovery[v,timepoint], squareform(correlations[timepoint/block_length],checks=False))[0]\n",
    "                sliding_window_correlations_single[i,v,timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "\n",
    "    \n",
    "        tc1 = pearsonr(true_recovery[timepoint], squareform(correlation1,checks=False))[0]\n",
    "        true_correlations1[timepoint] += 0.5 * (log(1+tc1) - log(1-tc1+1e-5))\n",
    "        tc2 = pearsonr(true_recovery[timepoint], squareform(correlation2,checks=False))[0]\n",
    "        true_correlations2[timepoint] += 0.5 * (log(1+tc2) - log(1-tc2+1e-5))\n",
    "           \n",
    "timecorr_correlations1_std = np.std(timecorr_correlations1,0)/sqrt(repetitions)\n",
    "timecorr_correlations1_std =  (np.exp(2*timecorr_correlations1_std) - 1)/(np.exp(2*timecorr_correlations1_std) + 1)\n",
    "timecorr_correlations1 = np.mean(timecorr_correlations1,0)\n",
    "# timecorr_correlations1 /= repetitions\n",
    "timecorr_correlations1 =  (np.exp(2*timecorr_correlations1) - 1)/(np.exp(2*timecorr_correlations1) + 1)\n",
    "\n",
    "timecorr_correlations2_std = np.std(timecorr_correlations2,0)/sqrt(repetitions)\n",
    "timecorr_correlations2_std =  (np.exp(2*timecorr_correlations2_std) - 1)/(np.exp(2*timecorr_correlations2_std) + 1)\n",
    "timecorr_correlations2 = np.mean(timecorr_correlations2,0)\n",
    "# timecorr_correlations2 /= repetitions\n",
    "timecorr_correlations2 =  (np.exp(2*timecorr_correlations2) - 1)/(np.exp(2*timecorr_correlations2) + 1)\n",
    "\n",
    "sliding_window_correlations1_std = np.std(sliding_window_correlations1,0)/sqrt(repetitions)\n",
    "sliding_window_correlations1_std =  (np.exp(2*sliding_window_correlations1_std) - 1)/(np.exp(2*sliding_window_correlations1_std) + 1)\n",
    "sliding_window_correlations1 = np.mean(sliding_window_correlations1,0)\n",
    "sliding_window_correlations1 =  (np.exp(2*sliding_window_correlations1) - 1)/(np.exp(2*sliding_window_correlations1) + 1)\n",
    "\n",
    "sliding_window_correlations2_std = np.std(sliding_window_correlations2,0)/sqrt(repetitions)\n",
    "sliding_window_correlations2_std =  (np.exp(2*sliding_window_correlations2_std) - 1)/(np.exp(2*sliding_window_correlations2_std) + 1)\n",
    "sliding_window_correlations2 = np.mean(sliding_window_correlations2,0)\n",
    "sliding_window_correlations2 =  (np.exp(2*sliding_window_correlations2) - 1)/(np.exp(2*sliding_window_correlations2) + 1)\n",
    "\n",
    "true_correlations1 /= repetitions\n",
    "true_correlations1 =  (np.exp(2*true_correlations1) - 1)/(np.exp(2*true_correlations1) + 1)\n",
    "\n",
    "true_correlations2 /= repetitions\n",
    "true_correlations2 =  (np.exp(2*true_correlations2) - 1)/(np.exp(2*true_correlations2) + 1)\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "# timecorr_correlations_single /= repetitions\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "\n",
    "sliding_window_correlations_single_std = np.std(sliding_window_correlations_single,0)/sqrt(repetitions)\n",
    "sliding_window_correlations_single_std =  (np.exp(2*sliding_window_correlations_single_std) - 1)/(np.exp(2*sliding_window_correlations_single_std) + 1)\n",
    "sliding_window_correlations_single = np.mean(sliding_window_correlations_single,0)\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "\n",
    "f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, sharey='row', sharex='col', figsize=(16,16))\n",
    "a1,a2= [ax1,ax2],[ax3,ax4]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# plt.suptitle(\"temporal ground truth linearly transforming from component A to component B over 500 timepoints\",fontsize=20)\n",
    "ax1.set_title(\"TimeCorr Performance\",fontsize=18)\n",
    "ax2.set_title(\"Sliding Window Performance\",fontsize=18)\n",
    "# a1[2].set_title(\"variance = 1000, sliding window = 25\",fontsize=18)\n",
    "# a1[3].set_title(\"variance = 1500, sliding window = 25\",fontsize=18)\n",
    "ax1.set_ylabel(\"correlation with end points\",fontsize=18)\n",
    "ax3.set_ylabel(\"correlation with ground truth\",fontsize=18)\n",
    "for v in range(var_num): \n",
    "    lower_limit, upper_limit = int(sliding_window_length[v]/2),(time_len-int(sliding_window_length[v]/2))\n",
    "    ax1.plot(range(time_len),timecorr_correlations1[v],c='C'+str(v),linestyle='-',alpha=1.0, label = \"TimeCorr variance = \"+str(variance[v]))\n",
    "    ax1.plot(range(time_len),timecorr_correlations2[v],c='C'+str(v),linestyle='-.',alpha=1.0)\n",
    "\n",
    "    ax2.plot(range(lower_limit,upper_limit),sliding_window_correlations1[v,lower_limit:upper_limit],c='C'+str(v),linestyle='-',alpha=1,label = \"window length = \"+str(sliding_window_length[v]))\n",
    "    ax2.plot(range(lower_limit,upper_limit),sliding_window_correlations2[v,lower_limit:upper_limit],c='C'+str(v),linestyle='-.',alpha=1)\n",
    "    \n",
    "\n",
    "    ax1.plot([range(time_len) for i in range(2)],[timecorr_correlations1[v]+timecorr_correlations1_std[v],timecorr_correlations1[v]-timecorr_correlations1_std[v]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax1.plot([range(time_len) for i in range(2)],[timecorr_correlations2[v]+timecorr_correlations2_std[v],timecorr_correlations2[v]-timecorr_correlations2_std[v]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax2.plot([range(lower_limit,upper_limit) for i in range(2)],[sliding_window_correlations1[v,lower_limit:upper_limit]+sliding_window_correlations1_std[v,lower_limit:upper_limit],sliding_window_correlations1[v,lower_limit:upper_limit]-sliding_window_correlations1_std[v,lower_limit:upper_limit]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax2.plot([range(lower_limit,upper_limit) for i in range(2)],[sliding_window_correlations2[v,lower_limit:upper_limit]+sliding_window_correlations2_std[v,lower_limit:upper_limit],sliding_window_correlations2[v,lower_limit:upper_limit]-sliding_window_correlations2_std[v,lower_limit:upper_limit]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "\n",
    "    ax3.plot(range(time_len),timecorr_correlations_single[v],c='C'+str(v),alpha=1,linestyle='-')\n",
    "    ax3.plot([range(time_len) for i in range(2)],[timecorr_correlations_single[v]+timecorr_correlations_single_std[v],timecorr_correlations_single[v]-timecorr_correlations_single_std[v]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax4.plot([range(lower_limit,upper_limit) for i in range(2)],[sliding_window_correlations_single[v,lower_limit:upper_limit]+sliding_window_correlations_single_std[v,lower_limit:upper_limit],sliding_window_correlations_single[v,lower_limit:upper_limit]-sliding_window_correlations_single_std[v,lower_limit:upper_limit]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax4.plot(range(lower_limit,upper_limit),sliding_window_correlations_single[v,lower_limit:upper_limit],c='C'+str(v),alpha=1,linestyle='-')\n",
    "    ax3.set_xlabel(\"time\",fontsize=18)\n",
    "    ax3.tick_params(labelsize=15)\n",
    "    ax4.set_xlabel(\"time\",fontsize=18)\n",
    "    ax4.tick_params(labelsize=15)\n",
    "#     a2[v].tick_params(labelsize=15)\n",
    "\n",
    "ax1.plot(range(time_len),true_correlations1,c='C'+str(v+1),linestyle='-',alpha=1,label = \"temporal ground truth\")\n",
    "ax1.plot(range(time_len),true_correlations2,c='C'+str(v+1),linestyle='-.',alpha=1)\n",
    "ax2.plot(range(time_len),true_correlations1,c='C'+str(v+1),linestyle='-',alpha=1,label = \"temporal ground truth\")\n",
    "ax2.plot(range(time_len),true_correlations2,c='C'+str(v+1),linestyle='-.',alpha=1)\n",
    "\n",
    "#     a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "#     a2[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "\n",
    "ax1.legend(loc='lower center')\n",
    "ax1.set_ylim(-0.2, 1.1)\n",
    "ax1.set_xlabel(\"time\",fontsize=18)\n",
    "ax1.tick_params(labelsize=15)\n",
    "\n",
    "ax2.legend(loc='lower center')\n",
    "ax2.set_ylim(-0.2, 1.1)\n",
    "ax2.set_xlabel(\"time\",fontsize=18)\n",
    "ax2.tick_params(labelsize=15)\n",
    "\n",
    "# ax3.legend(loc='lower center')\n",
    "ax3.set_ylim(-0.2, 1.1)\n",
    "ax3.set_xlabel(\"time\",fontsize=18)\n",
    "ax3.tick_params(labelsize=15)\n",
    "\n",
    "# ax4.legend(loc='lower center')\n",
    "ax4.set_ylim(-0.2, 1.1)\n",
    "ax4.set_xlabel(\"time\",fontsize=18)\n",
    "ax4.tick_params(labelsize=15)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "#break on end of first block###\n",
    "\n",
    "f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, sharey='row', sharex='col', figsize=(16,16))\n",
    "a1,a2= [ax1,ax2],[ax3,ax4]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# plt.suptitle(\"temporal ground truth linearly transforming from component A to component B over 500 timepoints\",fontsize=20)\n",
    "ax1.set_title(\"TimeCorr Performance\",fontsize=18)\n",
    "ax2.set_title(\"Sliding Window Performance\",fontsize=18)\n",
    "# a1[2].set_title(\"variance = 1000, sliding window = 25\",fontsize=18)\n",
    "# a1[3].set_title(\"variance = 1500, sliding window = 25\",fontsize=18)\n",
    "ax1.set_ylabel(\"correlation with end points\",fontsize=18)\n",
    "ax3.set_ylabel(\"correlation with ground truth\",fontsize=18)\n",
    "for v in range(var_num): \n",
    "    lower_limit, upper_limit = int(sliding_window_length[v]/2),(time_len-int(sliding_window_length[v]/2))\n",
    "    ax1.plot(range(time_len),timecorr_correlations1[v],c='C'+str(v),linestyle='-',alpha=1.0, label = \"TimeCorr variance = \"+str(variance[v]))\n",
    "    ax1.plot(range(time_len),timecorr_correlations2[v],c='C'+str(v),linestyle='-.',alpha=1.0)\n",
    "\n",
    "    ax2.plot(range(lower_limit,upper_limit),sliding_window_correlations1[v,lower_limit:upper_limit],c='C'+str(v),linestyle='-',alpha=1,label = \"window length = \"+str(sliding_window_length[v]))\n",
    "    ax2.plot(range(lower_limit,upper_limit),sliding_window_correlations2[v,lower_limit:upper_limit],c='C'+str(v),linestyle='-.',alpha=1)\n",
    "    \n",
    "\n",
    "    ax1.plot([range(time_len) for i in range(2)],[timecorr_correlations1[v]+timecorr_correlations1_std[v],timecorr_correlations1[v]-timecorr_correlations1_std[v]],c='C'+str(v),linestyle='-',alpha=0.05)\n",
    "    ax1.plot([range(time_len) for i in range(2)],[timecorr_correlations2[v]+timecorr_correlations2_std[v],timecorr_correlations2[v]-timecorr_correlations2_std[v]],c='C'+str(v),linestyle='-',alpha=0.05)\n",
    "    ax2.plot([range(lower_limit,upper_limit) for i in range(2)],[sliding_window_correlations1[v,lower_limit:upper_limit]+sliding_window_correlations1_std[v,lower_limit:upper_limit],sliding_window_correlations1[v,lower_limit:upper_limit]-sliding_window_correlations1_std[v,lower_limit:upper_limit]],c='C'+str(v),linestyle='-',alpha=0.1)\n",
    "    ax2.plot([range(lower_limit,upper_limit) for i in range(2)],[sliding_window_correlations2[v,lower_limit:upper_limit]+sliding_window_correlations2_std[v,lower_limit:upper_limit],sliding_window_correlations2[v,lower_limit:upper_limit]-sliding_window_correlations2_std[v,lower_limit:upper_limit]],c='C'+str(v),linestyle='-',alpha=0.1)\n",
    "\n",
    "    ax3.plot(range(time_len),timecorr_correlations_single[v],c='C'+str(v),alpha=1,linestyle='-')\n",
    "    ax3.plot([range(time_len) for i in range(2)],[timecorr_correlations_single[v]+timecorr_correlations_single_std[v],timecorr_correlations_single[v]-timecorr_correlations_single_std[v]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax4.plot([range(lower_limit,upper_limit) for i in range(2)],[sliding_window_correlations_single[v,lower_limit:upper_limit]+sliding_window_correlations_single_std[v,lower_limit:upper_limit],sliding_window_correlations_single[v,lower_limit:upper_limit]-sliding_window_correlations_single_std[v,lower_limit:upper_limit]],c='C'+str(v),linestyle='-',alpha=0.3)\n",
    "    ax4.plot(range(lower_limit,upper_limit),sliding_window_correlations_single[v,lower_limit:upper_limit],c='C'+str(v),alpha=1,linestyle='-')\n",
    "    ax3.set_xlabel(\"time\",fontsize=18)\n",
    "    ax3.tick_params(labelsize=15)\n",
    "    ax4.set_xlabel(\"time\",fontsize=18)\n",
    "    ax4.tick_params(labelsize=15)\n",
    "#     a2[v].tick_params(labelsize=15)\n",
    "\n",
    "ax1.plot(range(time_len),true_correlations1,c='C'+str(v+1),linestyle='-',alpha=1,label = \"temporal ground truth\")\n",
    "ax1.plot(range(time_len),true_correlations2,c='C'+str(v+1),linestyle='-.',alpha=1)\n",
    "ax2.plot(range(time_len),true_correlations1,c='C'+str(v+1),linestyle='-',alpha=1,label = \"temporal ground truth\")\n",
    "ax2.plot(range(time_len),true_correlations2,c='C'+str(v+1),linestyle='-.',alpha=1)\n",
    "\n",
    "#     a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "#     a2[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "\n",
    "ax1.legend(loc='lower center')\n",
    "ax1.set_ylim(-0.2, 1.1)\n",
    "ax1.set_xlabel(\"time\",fontsize=18)\n",
    "ax1.tick_params(labelsize=15)\n",
    "\n",
    "ax2.legend(loc='lower center')\n",
    "ax2.set_ylim(-0.2, 1.1)\n",
    "ax2.set_xlabel(\"time\",fontsize=18)\n",
    "ax2.tick_params(labelsize=15)\n",
    "\n",
    "# ax3.legend(loc='lower center')\n",
    "ax3.set_ylim(-0.2, 1.1)\n",
    "ax3.set_xlabel(\"time\",fontsize=18)\n",
    "ax3.tick_params(labelsize=15)\n",
    "\n",
    "# ax4.legend(loc='lower center')\n",
    "ax4.set_ylim(-0.2, 1.1)\n",
    "ax4.set_xlabel(\"time\",fontsize=18)\n",
    "ax4.tick_params(labelsize=15)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "##end second block##\n",
    "\n",
    "######## timecorr vs sliding window, different variances & ramp correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from math import log\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "variance = [100,500,1000,1500]\n",
    "sliding_window_length = 25\n",
    "repetitions=100\n",
    "var_num = len(variance)\n",
    "\n",
    "\n",
    "block_length = 1\n",
    "covariance_num = 1000\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_ramp_correlation_data():\n",
    "    global activations, correlations,correlation1,correlation2\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "    correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "    \n",
    "    while not is_pos_def(correlation1):\n",
    "        feature_map = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation1 = 2*np.dot(feature_map,feature_map.T)-1\n",
    "        correlation1 = correlation1/np.max(abs(correlation1))\n",
    "    while not is_pos_def(correlation2):\n",
    "        feature_map1 = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation2 = 2*np.dot(feature_map1,feature_map1.T)-1\n",
    "        correlation2 = correlation2/np.max(abs(correlation2))\n",
    "    for i in range(time_len):\n",
    "        cov_temp = (time_len-i)*0.5*(np.log(1+correlation1+1e-5) - np.log(1-correlation1+1e-5))/float(time_len)+i*0.5*(np.log(1+correlation2+1e-5) - np.log(1-correlation2+1e-5))/float(time_len)\n",
    "        correlations[i] =  (np.exp(2*cov_temp) - 1)/(np.exp(2*cov_temp) + 1)\n",
    "        activations[:,i] = np.dot(cholesky(correlations[i]),activations[:,i])\n",
    "\n",
    "lower_limit, upper_limit = int(sliding_window_length/2), int(time_len-sliding_window_length/2)\n",
    "\n",
    "timecorr_correlations1,timecorr_correlations2 = np.zeros([repetitions,var_num,time_len]),np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations1,sliding_window_correlations2 = np.zeros(time_len),np.zeros(time_len)\n",
    "true_correlations1,true_correlations2 = np.zeros([time_len]),np.zeros([time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations_single = np.zeros(time_len)\n",
    "random_correlations_single = np.zeros(time_len)\n",
    "\n",
    "color = ['b','r','k']\n",
    "\n",
    "timecorr_recovery = np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "#timecorr_recovery = np.zeros([var_num,time_len,(activation_num * (activation_num-1) / 2)])\n",
    "true_recovery = np.zeros([time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "#true_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\n",
    "for i in range(repetitions):\n",
    "    cholesky_ramp_correlation_data()\n",
    "    for v in range(var_num):\n",
    "        timecorr_recovery[v] = wcorr(activations,variance[v])\n",
    "    sliding_window_recovery = sliding_window(activations,sliding_window_length)\n",
    "#     print(sliding_window_recovery.shape)\n",
    "    for t in range(time_len):\n",
    "        true_recovery[t] = squareform(correlations[t],checks=False)\n",
    "    for timepoint in range(time_len):\n",
    "        for v in range(var_num):\n",
    "            otc1 = pearsonr(timecorr_recovery[v,timepoint], squareform(correlation1,checks=False))[0]\n",
    "            timecorr_correlations1[i,v,timepoint] += 0.5 * (log(1+otc1) - log(1-otc1))\n",
    "            otc2 = pearsonr(timecorr_recovery[v,timepoint], squareform(correlation2,checks=False))[0]\n",
    "            timecorr_correlations2[i,v,timepoint] += 0.5 * (log(1+otc2) - log(1-otc2))\n",
    "            \n",
    "            otcs = pearsonr(timecorr_recovery[v, timepoint], squareform(correlations[timepoint],checks=False))[0]\n",
    "            timecorr_correlations_single[i,v, timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "        \n",
    "        if timepoint>lower_limit-1 and timepoint<upper_limit:\n",
    "            #sc1 = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlation1,checks=False))[0]\n",
    "            sc1 = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlation1,checks=False))[0]\n",
    "            sliding_window_correlations1[timepoint] += 0.5 * (log(1+sc1) - log(1-sc1))\n",
    "            #sc2 = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlation2,checks=False))[0]\n",
    "            sc2 = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlation2,checks=False))[0]\n",
    "            sliding_window_correlations2[timepoint] += 0.5 * (log(1+sc2) - log(1-sc2))\n",
    "            #swc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[timepoint],checks=False))[0]\n",
    "            swc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[timepoint],checks=False))[0]\n",
    "            sliding_window_correlations_single[timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "\n",
    "    \n",
    "        tc1 = pearsonr(true_recovery[timepoint], squareform(correlation1,checks=False))[0]\n",
    "        true_correlations1[timepoint] += 0.5 * (log(1+tc1) - log(1-tc1+1e-5))\n",
    "        tc2 = pearsonr(true_recovery[timepoint], squareform(correlation2,checks=False))[0]\n",
    "        true_correlations2[timepoint] += 0.5 * (log(1+tc2) - log(1-tc2+1e-5))\n",
    "           \n",
    "timecorr_correlations1_std = np.std(timecorr_correlations1,0)/sqrt(repetitions)\n",
    "timecorr_correlations1_std =  (np.exp(2*timecorr_correlations1_std) - 1)/(np.exp(2*timecorr_correlations1_std) + 1)\n",
    "timecorr_correlations1 = np.mean(timecorr_correlations1,0)\n",
    "# timecorr_correlations1 /= repetitions\n",
    "timecorr_correlations1 =  (np.exp(2*timecorr_correlations1) - 1)/(np.exp(2*timecorr_correlations1) + 1)\n",
    "\n",
    "timecorr_correlations2_std = np.std(timecorr_correlations2,0)/sqrt(repetitions)\n",
    "timecorr_correlations2_std =  (np.exp(2*timecorr_correlations2_std) - 1)/(np.exp(2*timecorr_correlations2_std) + 1)\n",
    "timecorr_correlations2 = np.mean(timecorr_correlations2,0)\n",
    "# timecorr_correlations2 /= repetitions\n",
    "timecorr_correlations2 =  (np.exp(2*timecorr_correlations2) - 1)/(np.exp(2*timecorr_correlations2) + 1)\n",
    "\n",
    "sliding_window_correlations1 /= repetitions\n",
    "sliding_window_correlations1 =  (np.exp(2*sliding_window_correlations1) - 1)/(np.exp(2*sliding_window_correlations1) + 1)\n",
    "\n",
    "sliding_window_correlations2 /= repetitions\n",
    "sliding_window_correlations2 =  (np.exp(2*sliding_window_correlations2) - 1)/(np.exp(2*sliding_window_correlations2) + 1)\n",
    "\n",
    "true_correlations1 /= repetitions\n",
    "true_correlations1 =  (np.exp(2*true_correlations1) - 1)/(np.exp(2*true_correlations1) + 1)\n",
    "\n",
    "true_correlations2 /= repetitions\n",
    "true_correlations2 =  (np.exp(2*true_correlations2) - 1)/(np.exp(2*true_correlations2) + 1)\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "# timecorr_correlations_single /= repetitions\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2= [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# plt.suptitle(\"temporal ground truth linearly transforming from component A to component B over 500 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 100, sliding window = 25\",fontsize=18)\n",
    "a1[1].set_title(\"variance = 500, sliding window = 25\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 1000, sliding window = 25\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 1500, sliding window = 25\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. components\",fontsize=18)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=18)\n",
    "for v in range(var_num): \n",
    "    a1[v].plot(range(time_len),timecorr_correlations1[v],c=color[0],linestyle='-',alpha=1.0, label = \"timecorr recovery wrt component A\") \n",
    "    a1[v].plot(range(time_len),timecorr_correlations2[v],c=color[1],linestyle='-',alpha=1.0,label = \"timecorr recovery wrt component B\")\n",
    "    #a1[v].plot(range(sliding_window_length/2,time_len-sliding_window_length/2),sliding_window_correlations1[lower_limit:upper_limit],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\")\n",
    "    a1[v].plot(range(int(sliding_window_length/2), int(time_len-sliding_window_length/2)),sliding_window_correlations1[lower_limit:upper_limit],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\")\n",
    "    a1[v].plot(range(int(sliding_window_length/2),int(time_len-sliding_window_length/2)),sliding_window_correlations2[lower_limit:upper_limit],c=color[1],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component B\")\n",
    "    a1[v].plot(range(time_len),true_correlations1,c=color[0],linestyle='-.',alpha=0.5,label = \"temporal ground truth wrt component A\")\n",
    "    a1[v].plot(range(time_len),true_correlations2,c=color[1],linestyle='-.',alpha=0.5,label = \"temporal ground truth wrt component B\")\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "#         a1[v].legend(bbox_to_anchor=(2, 1), loc=1)\n",
    "    \n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[v],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "    a1[v].plot([range(time_len) for i in range(2)],[timecorr_correlations1[v]+timecorr_correlations1_std[v],timecorr_correlations1[v]-timecorr_correlations1_std[v]],c=color[0],linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    a1[v].plot([range(time_len) for i in range(2)],[timecorr_correlations2[v]+timecorr_correlations2_std[v],timecorr_correlations2[v]-timecorr_correlations2_std[v]],c=color[1],linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    a2[v].plot([range(time_len) for i in range(2)],[timecorr_correlations_single[v]+timecorr_correlations_single_std[v],timecorr_correlations_single[v]-timecorr_correlations_single_std[v]],c='r',linestyle='-',alpha=0.3, label = \"timecorr recovery wrt component A\")\n",
    "    a2[v].plot(range(lower_limit,upper_limit),sliding_window_correlations_single[lower_limit:upper_limit],c='b',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "#         a2[v].legend(bbox_to_anchor=(2, 1), loc=1)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "####end block 3#####\n",
    "\n",
    "######## timecorr vs sliding window, different variances & ramp correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "variance = 300\n",
    "sliding_window_length = [11,25,51,75]\n",
    "repetitions=100\n",
    "length_num = len(sliding_window_length)\n",
    "\n",
    "block_length = 1\n",
    "covariance_num = 300\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_ramp_correlation_data():\n",
    "    global activations, correlations,correlation1,correlation2\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "    correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "    \n",
    "    while not is_pos_def(correlation1):\n",
    "        feature_map = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation1 = 2*np.dot(feature_map,feature_map.T)-1\n",
    "        correlation1 = correlation1/np.max(abs(correlation1))\n",
    "    while not is_pos_def(correlation2):\n",
    "        feature_map1 = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation2 = 2*np.dot(feature_map1,feature_map1.T)-1\n",
    "        correlation2 = correlation2/np.max(abs(correlation2))\n",
    "    for i in range(time_len):\n",
    "        cov_temp = (time_len-i)*0.5*(np.log(1+correlation1+1e-5) - np.log(1-correlation1+1e-5))/float(time_len)+i*0.5*(np.log(1+correlation2+1e-5) - np.log(1-correlation2+1e-5))/float(time_len)\n",
    "        correlations[i] =  (np.exp(2*cov_temp) - 1)/(np.exp(2*cov_temp) + 1)\n",
    "        activations[:,i] = np.dot(cholesky(correlations[i]),activations[:,i])\n",
    "\n",
    "timecorr_correlations1,timecorr_correlations2 = np.zeros([repetitions,time_len]),np.zeros([repetitions,time_len])\n",
    "sliding_window_correlations1,sliding_window_correlations2 = np.zeros([length_num,time_len]),np.zeros([length_num,time_len])\n",
    "true_correlations1,true_correlations2 = np.zeros([time_len]),np.zeros([time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,time_len])\n",
    "sliding_window_correlations_single = np.zeros([length_num,time_len])\n",
    "color = ['b','r','k']\n",
    "\n",
    "timecorr_recovery= np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "#sliding_window_recovery = np.zeros([length_num, time_len,(activation_num * (activation_num-1) / 2)])\n",
    "sliding_window_recovery = np.zeros([length_num, time_len, int((activation_num * (activation_num-1) / 2))])\n",
    "true_recovery = np.zeros([time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "#true_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\n",
    "for i in range(repetitions):\n",
    "    cholesky_ramp_correlation_data()\n",
    "    timecorr_recovery = wcorr(activations,variance)\n",
    "    for t in range(time_len):\n",
    "        true_recovery[t] = squareform(correlations[t],checks=False)\n",
    "    \n",
    "    for v in range(length_num):\n",
    "        sliding_window_recovery[v,(sliding_window_length[v]-1):] = sliding_window(activations,sliding_window_length[v])\n",
    "    \n",
    "    for timepoint in range(time_len):\n",
    "        for v in range(length_num):\n",
    "            if timepoint>int(sliding_window_length[v]/2)-1 and timepoint<time_len-int(sliding_window_length[v]/2):\n",
    "                sc1 = pearsonr(sliding_window_recovery[v,timepoint+int(sliding_window_length[v]/2)], squareform(correlation1,checks=False))[0]\n",
    "                sliding_window_correlations1[v,timepoint] += 0.5 * (log(1+sc1) - log(1-sc1))\n",
    "                sc2 = pearsonr(sliding_window_recovery[v,timepoint+int(sliding_window_length[v]/2)], squareform(correlation2,checks=False))[0]\n",
    "                sliding_window_correlations2[v,timepoint] += 0.5 * (log(1+sc2) - log(1-sc2))\n",
    "\n",
    "                swc = pearsonr(sliding_window_recovery[v,timepoint+int(sliding_window_length[v]/2)], squareform(correlations[timepoint],checks=False))[0]\n",
    "                sliding_window_correlations_single[v,timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "        \n",
    "        \n",
    "        otc1 = pearsonr(timecorr_recovery[timepoint], squareform(correlation1,checks=False))[0]\n",
    "        timecorr_correlations1[i,timepoint] += 0.5 * (log(1+otc1) - log(1-otc1))\n",
    "        otc2 = pearsonr(timecorr_recovery[timepoint], squareform(correlation2,checks=False))[0]\n",
    "        timecorr_correlations2[i,timepoint] += 0.5 * (log(1+otc2) - log(1-otc2))\n",
    "\n",
    "        otcs = pearsonr(timecorr_recovery[timepoint], squareform(correlations[timepoint],checks=False))[0]\n",
    "        timecorr_correlations_single[i,timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "\n",
    "        tc1 = pearsonr(true_recovery[timepoint], squareform(correlation1,checks=False))[0]\n",
    "        true_correlations1[timepoint] += 0.5 * (log(1+tc1) - log(1-tc1+1e-5))\n",
    "        tc2 = pearsonr(true_recovery[timepoint], squareform(correlation2,checks=False))[0]\n",
    "        true_correlations2[timepoint] += 0.5 * (log(1+tc2) - log(1-tc2+1e-5))\n",
    "\n",
    "\n",
    "timecorr_correlations1_std = np.std(timecorr_correlations1,0)/sqrt(repetitions)\n",
    "timecorr_correlations1_std =  (np.exp(2*timecorr_correlations1_std) - 1)/(np.exp(2*timecorr_correlations1_std) + 1)\n",
    "timecorr_correlations1 = np.mean(timecorr_correlations1,0)\n",
    "timecorr_correlations1 =  (np.exp(2*timecorr_correlations1) - 1)/(np.exp(2*timecorr_correlations1) + 1)\n",
    "\n",
    "timecorr_correlations2_std = np.std(timecorr_correlations2,0)/sqrt(repetitions)\n",
    "timecorr_correlations2_std =  (np.exp(2*timecorr_correlations2_std) - 1)/(np.exp(2*timecorr_correlations2_std) + 1)\n",
    "timecorr_correlations2 = np.mean(timecorr_correlations2,0)\n",
    "timecorr_correlations2 =  (np.exp(2*timecorr_correlations2) - 1)/(np.exp(2*timecorr_correlations2) + 1)\n",
    "\n",
    "sliding_window_correlations1 /= repetitions\n",
    "sliding_window_correlations1 =  (np.exp(2*sliding_window_correlations1) - 1)/(np.exp(2*sliding_window_correlations1) + 1)\n",
    "\n",
    "sliding_window_correlations2 /= repetitions\n",
    "sliding_window_correlations2 =  (np.exp(2*sliding_window_correlations2) - 1)/(np.exp(2*sliding_window_correlations2) + 1)\n",
    "\n",
    "true_correlations1 /= repetitions\n",
    "true_correlations1 =  (np.exp(2*true_correlations1) - 1)/(np.exp(2*true_correlations1) + 1)\n",
    "\n",
    "true_correlations2 /= repetitions\n",
    "true_correlations2 =  (np.exp(2*true_correlations2) - 1)/(np.exp(2*true_correlations2) + 1)\n",
    "\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "# plt.suptitle(\"temporal ground truth linearly transforming from component A to component B over 1000 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 300, sliding window = 11\",fontsize=18)\n",
    "a1[1].set_title(\"variance = 300, sliding window = 25\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 300, sliding window = 51\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 300, sliding window = 101\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. components\",fontsize=18)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=18)\n",
    "\n",
    "for v in range(length_num): \n",
    "    a1[v].plot(range(time_len),timecorr_correlations1[:],c=color[0],linestyle='-',alpha=1.0, label = \"timecorr recovery wrt component A\")\n",
    "    a1[v].plot([range(time_len) for i in range(2)],[timecorr_correlations1+timecorr_correlations1_std,timecorr_correlations1-timecorr_correlations1_std],c=color[0],linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    a1[v].plot(range(time_len),timecorr_correlations2[:],c=color[1],linestyle='-',alpha=1.0,label = \"timecorr recovery wrt component B\")\n",
    "    a1[v].plot([range(time_len) for i in range(2)],[timecorr_correlations2+timecorr_correlations2_std,timecorr_correlations2-timecorr_correlations2_std],c=color[1],linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    #a1[v].plot(range(sliding_window_length[v]/2,time_len-sliding_window_length[v]/2),sliding_window_correlations1[v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2)],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\")\n",
    "    a1[v].plot(range(int(sliding_window_length[v]/2),int(time_len-sliding_window_length[v]/2)),sliding_window_correlations1[v,int(sliding_window_length[v]/2):int((time_len-sliding_window_length[v]/2))],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\")\n",
    "    #a1[v].plot(range(sliding_window_length[v]/2,time_len-sliding_window_length[v]/2),sliding_window_correlations2[v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2)],c=color[1],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component B\")\n",
    "    a1[v].plot(range(int(sliding_window_length[v]/2),int(time_len-sliding_window_length[v]/2)),sliding_window_correlations2[v,int(sliding_window_length[v]/2):int((time_len-sliding_window_length[v]/2))],c=color[1],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component B\")\n",
    "    a1[v].plot(range(time_len),true_correlations1[:],c=color[0],linestyle='-.',alpha=0.5,label = \"temporal ground truth wrt component A\")\n",
    "    a1[v].plot(range(time_len),true_correlations2[:],c=color[1],linestyle='-.',alpha=0.5,label = \"temporal ground truth wrt component B\")\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "#     if v==length_num-1:\n",
    "#         a1[v].legend(bbox_to_anchor=(2, 1), loc=1)\n",
    "    \n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[:],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "    a2[v].plot([range(time_len) for i in range(2)],[timecorr_correlations_single+timecorr_correlations_single_std,timecorr_correlations_single-timecorr_correlations_single_std],c='r',linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    #a2[v].plot(range(sliding_window_length[v]/2,time_len-sliding_window_length[v]/2),sliding_window_correlations_single[v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2)],c='b',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].plot(range(int(sliding_window_length[v]/2),int(time_len-sliding_window_length[v]/2)),sliding_window_correlations_single[v, int(sliding_window_length[v]/2):int((time_len-sliding_window_length[v]/2))],c='b',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "#     if v==length_num-1:\n",
    "#         a2[v].legend(bbox_to_anchor=(2, 1), loc=1)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "### end block 4###\n",
    "\n",
    "######## timecorr vs sliding window, different variances & block correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "variance = [100,500,1000,1500]\n",
    "sliding_window_length = 51\n",
    "repetitions=100\n",
    "var_num = len(variance)\n",
    "block_length = 100\n",
    "covariance_num = 10\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_block_correlation_data(bl,cn,an):\n",
    "    global activations, correlations\n",
    "    block_length = bl\n",
    "    covariance_num = cn\n",
    "    activation_num = an\n",
    "    time_len = block_length * covariance_num\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    \n",
    "    activations = np.random.normal(0,1,[activation_num, time_len])\n",
    "\n",
    "    for i in range(covariance_num):\n",
    "        while not is_pos_def(correlations[i]):\n",
    "            temp = np.random.normal(0,1,[activation_num,activation_num])\n",
    "            correlations[i] = np.dot(temp,temp.T)\n",
    "            correlations[i] = correlations[i]/np.max(abs(correlations[i]))\n",
    "    \n",
    "    for i in range(covariance_num):\n",
    "        activations[:,(i*block_length):((i+1)*block_length)]=np.dot(cholesky(correlations[i]),activations[:,(i*block_length):((i+1)*block_length)])\n",
    "\n",
    "timecorr_correlations = np.zeros([var_num,covariance_num,time_len])\n",
    "sliding_window_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([var_num,time_len])\n",
    "sliding_window_correlations_single = np.zeros(time_len)\n",
    "\n",
    "true_correlations1,true_correlations2 = np.zeros([time_len]),np.zeros([time_len])\n",
    "\n",
    "timecorr_recovery = np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "\n",
    "for r in range(repetitions):\n",
    "    for i in range(covariance_num):\n",
    "        cholesky_block_correlation_data(block_length,covariance_num,activation_num)\n",
    "        sliding_window_recovery = sliding_window(activations,sliding_window_length)\n",
    "        for v in range(var_num):\n",
    "            timecorr_recovery[v] = wcorr(activations, variance[v])\n",
    "        for timepoint in range(time_len):\n",
    "            if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "                #sc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[i],checks=False))[0]\n",
    "                sc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[i],checks=False))[0]\n",
    "                sliding_window_correlations[i,timepoint] += 0.5 * (log(1+sc) - log(1-sc))\n",
    "            \n",
    "            for v in range(var_num):\n",
    "                otc = pearsonr(timecorr_recovery[v,timepoint], squareform(correlations[i],checks=False))[0]\n",
    "                timecorr_correlations[v,i,timepoint] += 0.5 * (log(1+otc) - log(1-otc))\n",
    "           \n",
    "    for timepoint in range(time_len):\n",
    "        if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "            #swc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            swc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            sliding_window_correlations_single[timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "\n",
    "        for v in range(var_num):\n",
    "            otcs = pearsonr(timecorr_recovery[v, timepoint], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            timecorr_correlations_single[v, timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "        \n",
    "\n",
    "timecorr_correlations /= repetitions\n",
    "timecorr_correlations = (np.exp(2*timecorr_correlations) - 1)/(np.exp(2*timecorr_correlations) + 1)\n",
    "\n",
    "sliding_window_correlations /= repetitions\n",
    "sliding_window_correlations = (np.exp(2*sliding_window_correlations) - 1)/(np.exp(2*sliding_window_correlations) + 1)\n",
    "\n",
    "timecorr_correlations_single /= repetitions\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "\n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# plt.suptitle(\"10 discrete correlations, each occupying a block of 100 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 100, sliding window = 51\",fontsize=18)\n",
    "a1[0].set_ylim(-0.2, 1.1)\n",
    "a1[1].set_title(\"variance = 500, sliding window = 51\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 1000, sliding window = 51\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 1500, sliding window = 51\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. ground truths\",fontsize=18)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=18)\n",
    "a2[0].set_ylim(-0.2, 1.1)\n",
    "\n",
    "for v in range(var_num): \n",
    "    for i in range(covariance_num):\n",
    "        a1[v].plot(range(time_len),timecorr_correlations[v,i],c='C'+str(i),alpha=1,linestyle='-', label=\"timecorr recovery wrt ground truth \"+str(i))\n",
    "#        a1[v].plot(range(sliding_window_length/2,time_len-sliding_window_length/2),sliding_window_correlations[i,sliding_window_length/2:time_len-sliding_window_length/2],c='C'+str(i),alpha=0.5,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))\n",
    "        a1[v].plot(range(int(sliding_window_length/2),int(time_len-sliding_window_length/2)),sliding_window_correlations[i, int(sliding_window_length/2):int(time_len-sliding_window_length/2)],c='C'+str(i),alpha=0.5,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))\n",
    "        ylim1, ylim2 = int(a1[v].get_ylim()[0]*10)+1,int(a1[v].get_ylim()[1]*10)+1\n",
    "        a1[v].plot(np.tile([[i*100] for i in range(1,10)],[1,ylim2-ylim1]).T,np.tile(np.array([i/10.0 for i in range(ylim1,ylim2)]),[9,1]).T,linestyle=\"--\")\n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[v],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "#    a2[v].plot(range(sliding_window_length/2,time_len-sliding_window_length/2),sliding_window_correlations_single[sliding_window_length/2:time_len-sliding_window_length/2],c='C1',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].plot(range(int(sliding_window_length/2),int(time_len-sliding_window_length/2)),sliding_window_correlations_single[ int(sliding_window_length/2): int(time_len-sliding_window_length/2)],c='C1',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    ylim1, ylim2 = int(a1[v].get_ylim()[0]*10)+1,int(a1[v].get_ylim()[1]*10)+1\n",
    "    a2[v].plot(np.tile([[i*100] for i in range(1,10)],[1,ylim2-ylim1]).T,np.tile(np.array([i/10.0 for i in range(ylim1,ylim2)]),[9,1]).T,linestyle=\"--\")\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "a1[0].legend('upper right')\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "#end block 4# \n",
    "\n",
    "#start block 5#\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "# plt.suptitle(\"10 discrete correlations, each occupying a block of 100 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 100, sliding window = 51\",fontsize=18)\n",
    "a1[0].set_ylim(-0.2, 1.1)\n",
    "a1[1].set_title(\"variance = 500, sliding window = 51\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 1000, sliding window = 51\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 1500, sliding window = 51\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. ground truths\",fontsize=18)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=18)\n",
    "a2[0].set_ylim(-0.2, 1.1)\n",
    "\n",
    "for v in range(var_num): \n",
    "    for i in range(covariance_num):\n",
    "        a1[v].plot(range(time_len),timecorr_correlations[v,i],c='C'+str(i),alpha=0.3,linestyle='-', label=\"timecorr recovery wrt ground truth \"+str(i))\n",
    "#        a1[v].plot(range(sliding_window_length/2,time_len-sliding_window_length/2),sliding_window_correlations[i,sliding_window_length/2:time_len-sliding_window_length/2],c='C'+str(i),alpha=1,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))\n",
    "        a1[v].plot(range(int(sliding_window_length/2),int(time_len-sliding_window_length/2)),sliding_window_correlations[i, int(sliding_window_length/2): int(time_len-sliding_window_length/2)],c='C'+str(i),alpha=1,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))\n",
    "        ylim1, ylim2 = int(a1[v].get_ylim()[0]*10),int(a1[v].get_ylim()[1]*10)+1\n",
    "    a1[v].plot(np.tile([[i*100] for i in range(1,10)],[1,ylim2-ylim1]).T,np.tile(np.array([i/10.0 for i in range(ylim1,ylim2)]),[9,1]).T,linestyle=\"-\", c='black',alpha=0.3)\n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[v],c='r',alpha=0.3,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "   # a2[v].plot(range(sliding_window_length/2,time_len-sliding_window_length/2),sliding_window_correlations_single[sliding_window_length/2:time_len-sliding_window_length/2],c='C1',alpha=1,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].plot(range( int(sliding_window_length/2), int(time_len-sliding_window_length/2)),sliding_window_correlations_single[ int(sliding_window_length/2): int(time_len-sliding_window_length/2)],c='C1',alpha=1,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    ylim1, ylim2 = int(a1[v].get_ylim()[0]*10),int(a1[v].get_ylim()[1]*10)+1\n",
    "    a2[v].plot(np.tile([[i*100] for i in range(1,10)],[1,ylim2-ylim1]).T,np.tile(np.array([i/10.0 for i in range(ylim1,ylim2)]),[9,1]).T,linestyle=\"-\", c='black',alpha=0.3)\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "#end block 5#\n",
    "\n",
    "#start block 6#\n",
    "######## timecorr vs sliding window, different variances & block correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "variance = [10,100,500,1000]\n",
    "sliding_window_length = 11\n",
    "repetitions=100\n",
    "var_num = len(variance)\n",
    "block_length = 11\n",
    "covariance_num = 2\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_block_correlation_data(bl,cn,an):\n",
    "    global activations, correlations\n",
    "    block_length = bl\n",
    "    covariance_num = cn\n",
    "    activation_num = an\n",
    "    time_len = block_length * covariance_num\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    \n",
    "    activations = np.random.normal(0,1,[activation_num, time_len])\n",
    "\n",
    "    for i in range(covariance_num):\n",
    "        while not is_pos_def(correlations[i]):\n",
    "            temp = np.random.normal(0,1,[activation_num,activation_num])\n",
    "            correlations[i] = np.dot(temp,temp.T)\n",
    "            correlations[i] = correlations[i]/np.max(abs(correlations[i]))\n",
    "    \n",
    "    for i in range(covariance_num):\n",
    "        activations[:,(i*block_length):((i+1)*block_length)]=np.dot(cholesky(correlations[i]),activations[:,(i*block_length):((i+1)*block_length)])\n",
    "\n",
    "timecorr_correlations = np.zeros([repetitions,var_num,covariance_num,time_len])\n",
    "sliding_window_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations_single = np.zeros(time_len)\n",
    "\n",
    "true_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_recovery = np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "\n",
    "for r in range(repetitions):\n",
    "    for i in range(covariance_num):\n",
    "        cholesky_block_correlation_data(block_length,covariance_num,activation_num)\n",
    "        sliding_window_recovery = sliding_window(activations,sliding_window_length)\n",
    "        for v in range(var_num):\n",
    "            timecorr_recovery[v] = wcorr(activations, variance[v])\n",
    "        for timepoint in range(time_len):\n",
    "            #if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "            if timepoint>int(int(sliding_window_length/2)-1) and timepoint<time_len-(int(sliding_window_length/2)):\n",
    "                #sc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[i],checks=False))[0]\n",
    "                sc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[i],checks=False))[0]\n",
    "                sliding_window_correlations[i,timepoint] += 0.5 * (log(1+sc) - log(1-sc))\n",
    "            \n",
    "            #tc = pearsonr(squareform(correlations[timepoint/block_length],checks=False), squareform(correlations[i],checks=False))[0]\n",
    "            tc = pearsonr(squareform(correlations[int(timepoint/block_length)],checks=False), squareform(correlations[i],checks=False))[0]\n",
    "            true_correlations[i,timepoint] += 0.5 * (log(1+tc) - log(1-tc+1e-5))\n",
    "            \n",
    "            for v in range(var_num):\n",
    "                otc = pearsonr(timecorr_recovery[v,timepoint], squareform(correlations[i],checks=False))[0]\n",
    "                timecorr_correlations[r,v,i,timepoint] += 0.5 * (log(1+otc) - log(1-otc))\n",
    "           \n",
    "    for timepoint in range(time_len):\n",
    "        if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "            #swc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            swc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            sliding_window_correlations_single[timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "\n",
    "        for v in range(var_num):\n",
    "            otcs = pearsonr(timecorr_recovery[v, timepoint], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            timecorr_correlations_single[r,v, timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "\n",
    "timecorr_correlations_std = np.std(timecorr_correlations,0)/sqrt(repetitions)\n",
    "timecorr_correlations_std =  (np.exp(2*timecorr_correlations_std) - 1)/(np.exp(2*timecorr_correlations_std) + 1)\n",
    "timecorr_correlations = np.mean(timecorr_correlations,0)\n",
    "timecorr_correlations = (np.exp(2*timecorr_correlations) - 1)/(np.exp(2*timecorr_correlations) + 1)\n",
    "\n",
    "sliding_window_correlations /= repetitions\n",
    "sliding_window_correlations = (np.exp(2*sliding_window_correlations) - 1)/(np.exp(2*sliding_window_correlations) + 1)\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "\n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "true_correlations /= repetitions\n",
    "true_correlations =  (np.exp(2*true_correlations) - 1)/(np.exp(2*true_correlations) + 1)\n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "# plt.suptitle(\"10 discrete correlations, each occupying a block of 100 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 10, sliding window = 11\",fontsize=18)\n",
    "a1[1].set_title(\"variance = 100, sliding window = 11\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 500, sliding window = 11\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 1000, sliding window = 11\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. ground truths\",fontsize=18)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=18)\n",
    "lower_limit,upper_limit = int(sliding_window_length/2),time_len-int(sliding_window_length/2)\n",
    "for v in range(var_num): \n",
    "    for i in range(covariance_num):\n",
    "        a1[v].plot(range(time_len),timecorr_correlations[v,i],c='C'+str(i),alpha=1,linestyle='-', label=\"timecorr recovery wrt ground truth \"+str(i))\n",
    "        a1[v].plot([range(time_len) for z in range(2)],[timecorr_correlations[v,i]+timecorr_correlations_std[v,i],timecorr_correlations[v,i]-timecorr_correlations_std[v,i]],c='C'+str(i),linestyle='-',alpha=0.2, label = \"timecorr recovery wrt component A\")\n",
    "        a1[v].plot(range(lower_limit,upper_limit),sliding_window_correlations[i,lower_limit:upper_limit],c='C'+str(i),alpha=0.5,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))    \n",
    "        a1[v].plot(range(time_len),true_correlations[i],c='C'+str(i),alpha=1,linestyle='-.')\n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[v],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "    a2[v].plot([range(time_len) for i in range(2)],[timecorr_correlations_single[v]+timecorr_correlations_single_std[v],timecorr_correlations_single[v]-timecorr_correlations_single_std[v]],c='r',linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    a2[v].plot(range(lower_limit,upper_limit),sliding_window_correlations_single[lower_limit:upper_limit],c='C1',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "#         a1[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a2[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a3[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a4[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "#end block 6#\n",
    "\n",
    "#Start block 7#\n",
    "######## timecorr vs sliding window, different variances & block correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "variance = [10,100,500,1000]\n",
    "sliding_window_length = 25\n",
    "repetitions=100\n",
    "var_num = len(variance)\n",
    "block_length = 50\n",
    "covariance_num = 2\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_block_correlation_data(bl,cn,an):\n",
    "    global activations, correlations\n",
    "    block_length = bl\n",
    "    covariance_num = cn\n",
    "    activation_num = an\n",
    "    time_len = block_length * covariance_num\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    \n",
    "    activations = np.random.normal(0,1,[activation_num, time_len])\n",
    "\n",
    "    for i in range(covariance_num):\n",
    "        while not is_pos_def(correlations[i]):\n",
    "            temp = np.random.normal(0,1,[activation_num,activation_num])\n",
    "            correlations[i] = np.dot(temp,temp.T)\n",
    "            correlations[i] = correlations[i]/np.max(abs(correlations[i]))\n",
    "    \n",
    "    for i in range(covariance_num):\n",
    "        activations[:,(i*block_length):((i+1)*block_length)]=np.dot(cholesky(correlations[i]),activations[:,(i*block_length):((i+1)*block_length)])\n",
    "\n",
    "timecorr_correlations = np.zeros([repetitions,var_num,covariance_num,time_len])\n",
    "sliding_window_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations_single = np.zeros(time_len)\n",
    "\n",
    "true_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_recovery = np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "#timecorr_recovery = np.zeros([var_num,time_len,(activation_num * (activation_num-1) / 2)])\n",
    "\n",
    "for r in range(repetitions):\n",
    "    for i in range(covariance_num):\n",
    "        cholesky_block_correlation_data(block_length,covariance_num,activation_num)\n",
    "        sliding_window_recovery = sliding_window(activations,sliding_window_length)\n",
    "        for v in range(var_num):\n",
    "            timecorr_recovery[v] = wcorr(activations, variance[v])\n",
    "        for timepoint in range(time_len):\n",
    "            if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "                #sc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[i],checks=False))[0]\n",
    "                sc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[i],checks=False))[0]\n",
    "                sliding_window_correlations[i,timepoint] += 0.5 * (log(1+sc) - log(1-sc))\n",
    "            \n",
    "            #tc = pearsonr(squareform(correlations[timepoint/block_length],checks=False), squareform(correlations[i],checks=False))[0]\n",
    "            tc = pearsonr(squareform(correlations[int(timepoint/block_length)],checks=False), squareform(correlations[i],checks=False))[0]\n",
    "            true_correlations[i,timepoint] += 0.5 * (log(1+tc) - log(1-tc+1e-5))\n",
    "            \n",
    "            for v in range(var_num):\n",
    "                otc = pearsonr(timecorr_recovery[v,timepoint], squareform(correlations[i],checks=False))[0]\n",
    "                timecorr_correlations[r,v,i,timepoint] += 0.5 * (log(1+otc) - log(1-otc))\n",
    "for timepoint in range(time_len):\n",
    "        #if timepoint>int(int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "        if timepoint>int(int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2)): \n",
    "            #swc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "             swc = pearsonr(sliding_window_recovery[int(np.divide(timepoint-sliding_window_length,2))], squareform(correlations[int(timepoint//block_length)],checks=False))[0]\n",
    "            #swc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[timepoint/block_length],checks=False))[0]\n",
    "             sliding_window_correlations_single[timepoint]+= 0.5 * (log(1+swc) - log(1-swc))\n",
    "\n",
    "        for v in range(var_num):\n",
    "            otcs = pearsonr(timecorr_recovery[v, timepoint], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            timecorr_correlations_single[r,v, timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "\n",
    "timecorr_correlations_std = np.std(timecorr_correlations,0)/sqrt(repetitions)\n",
    "timecorr_correlations_std =  (np.exp(2*timecorr_correlations_std) - 1)/(np.exp(2*timecorr_correlations_std) + 1)\n",
    "timecorr_correlations = np.mean(timecorr_correlations,0)\n",
    "timecorr_correlations = (np.exp(2*timecorr_correlations) - 1)/(np.exp(2*timecorr_correlations) + 1)\n",
    "\n",
    "sliding_window_correlations /= repetitions\n",
    "sliding_window_correlations = (np.exp(2*sliding_window_correlations) - 1)/(np.exp(2*sliding_window_correlations) + 1)\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "\n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "true_correlations /= repetitions\n",
    "true_correlations =  (np.exp(2*true_correlations) - 1)/(np.exp(2*true_correlations) + 1)\n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "# plt.suptitle(\"10 discrete correlations, each occupying a block of 100 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 10, sliding window = 25\",fontsize=18)\n",
    "a1[1].set_title(\"variance = 100, sliding window = 25\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 500, sliding window = 25\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 1000, sliding window = 25\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. ground truths\",fontsize=16)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=16)\n",
    "lower_limit,upper_limit = int(sliding_window_length/2),time_len-int(sliding_window_length/2)\n",
    "for v in range(var_num): \n",
    "    for i in range(covariance_num):\n",
    "        a1[v].plot(range(time_len),timecorr_correlations[v,i],c='C'+str(i),alpha=1,linestyle='-', label=\"timecorr recovery wrt ground truth \"+str(i))\n",
    "        a1[v].plot([range(time_len) for z in range(2)],[timecorr_correlations[v,i]+timecorr_correlations_std[v,i],timecorr_correlations[v,i]-timecorr_correlations_std[v,i]],c='C'+str(i),linestyle='-',alpha=0.2, label = \"timecorr recovery wrt component A\")\n",
    "        a1[v].plot(range(lower_limit,upper_limit),sliding_window_correlations[i,lower_limit:upper_limit],c='C'+str(i),alpha=0.5,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))    \n",
    "        a1[v].plot(range(time_len),true_correlations[i],c='C'+str(i),alpha=1,linestyle='-.')\n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[v],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "    a2[v].plot([range(time_len) for i in range(2)],[timecorr_correlations_single[v]+timecorr_correlations_single_std[v],timecorr_correlations_single[v]-timecorr_correlations_single_std[v]],c='r',linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    a2[v].plot(range(lower_limit,upper_limit),sliding_window_correlations_single[lower_limit:upper_limit],c='C1',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "#         a1[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a2[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a3[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a4[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.show()\n",
    "                         \n",
    "#end block 7#\n",
    "\n",
    "#start block8#\n",
    "######## timecorr vs sliding window, different variances & block correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "variance = [10,100,500,1000]\n",
    "sliding_window_length = 51\n",
    "repetitions=100\n",
    "var_num = len(variance)\n",
    "block_length = 250\n",
    "covariance_num = 2\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_block_correlation_data(bl,cn,an):\n",
    "    global activations, correlations\n",
    "    block_length = bl\n",
    "    covariance_num = cn\n",
    "    activation_num = an\n",
    "    time_len = block_length * covariance_num\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    \n",
    "    activations = np.random.normal(0,1,[activation_num, time_len])\n",
    "\n",
    "    for i in range(covariance_num):\n",
    "        while not is_pos_def(correlations[i]):\n",
    "            temp = np.random.normal(0,1,[activation_num,activation_num])\n",
    "            correlations[i] = np.dot(temp,temp.T)\n",
    "            correlations[i] = correlations[i]/np.max(abs(correlations[i]))\n",
    "    \n",
    "    for i in range(covariance_num):\n",
    "        activations[:,(i*block_length):((i+1)*block_length)]=np.dot(cholesky(correlations[i]),activations[:,(i*block_length):((i+1)*block_length)])\n",
    "\n",
    "timecorr_correlations = np.zeros([repetitions,var_num,covariance_num,time_len])\n",
    "sliding_window_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,var_num,time_len])\n",
    "sliding_window_correlations_single = np.zeros(time_len)\n",
    "\n",
    "true_correlations = np.zeros([covariance_num,time_len])\n",
    "\n",
    "timecorr_recovery = np.zeros([var_num,time_len, int((activation_num * (activation_num-1) / 2))])\n",
    "\n",
    "for r in range(repetitions):\n",
    "    for i in range(covariance_num):\n",
    "        cholesky_block_correlation_data(block_length,covariance_num,activation_num)\n",
    "        sliding_window_recovery = sliding_window(activations,sliding_window_length)\n",
    "        for v in range(var_num):\n",
    "            timecorr_recovery[v] = wcorr(activations, variance[v])\n",
    "        for timepoint in range(time_len):\n",
    "            if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "                #sc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[i],checks=False))[0]\n",
    "                sc = pearsonr(sliding_window_recovery[int(timepoint-sliding_window_length/2)], squareform(correlations[i],checks=False))[0]\n",
    "                sliding_window_correlations[i,timepoint] += 0.5 * (log(1+sc) - log(1-sc))\n",
    "            \n",
    "            #tc = pearsonr(squareform(correlations[timepoint/block_length],checks=False), squareform(correlations[i],checks=False))[0]\n",
    "            tc = pearsonr(squareform(correlations[int(timepoint/block_length)],checks=False), squareform(correlations[i],checks=False))[0]\n",
    "\n",
    "            true_correlations[i,timepoint] += 0.5 * (log(1+tc) - log(1-tc+1e-5))\n",
    "            \n",
    "            for v in range(var_num):\n",
    "                otc = pearsonr(timecorr_recovery[v,timepoint], squareform(correlations[i],checks=False))[0]\n",
    "                timecorr_correlations[r,v,i,timepoint] += 0.5 * (log(1+otc) - log(1-otc))\n",
    "           \n",
    "    for timepoint in range(time_len):\n",
    "        if timepoint>int(sliding_window_length/2)-1 and timepoint<time_len-int(sliding_window_length/2): \n",
    "            #swc = pearsonr(sliding_window_recovery[timepoint-sliding_window_length/2], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            sliding_window_correlations_single[timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "\n",
    "        for v in range(var_num):\n",
    "            otcs = pearsonr(timecorr_recovery[v, timepoint], squareform(correlations[int(timepoint/block_length)],checks=False))[0]\n",
    "            timecorr_correlations_single[r,v, timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "\n",
    "timecorr_correlations_std = np.std(timecorr_correlations,0)/sqrt(repetitions)\n",
    "timecorr_correlations_std =  (np.exp(2*timecorr_correlations_std) - 1)/(np.exp(2*timecorr_correlations_std) + 1)\n",
    "timecorr_correlations = np.mean(timecorr_correlations,0)\n",
    "timecorr_correlations = (np.exp(2*timecorr_correlations) - 1)/(np.exp(2*timecorr_correlations) + 1)\n",
    "\n",
    "sliding_window_correlations /= repetitions\n",
    "sliding_window_correlations = (np.exp(2*sliding_window_correlations) - 1)/(np.exp(2*sliding_window_correlations) + 1)\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "\n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "true_correlations /= repetitions\n",
    "true_correlations =  (np.exp(2*true_correlations) - 1)/(np.exp(2*true_correlations) + 1)\n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,12))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "# plt.suptitle(\"10 discrete correlations, each occupying a block of 100 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 10, sliding window = 25\",fontsize=18)\n",
    "a1[1].set_title(\"variance = 100, sliding window = 25\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 500, sliding window = 25\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 1000, sliding window = 25\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. ground truths\",fontsize=16)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=16)\n",
    "lower_limit,upper_limit = int(sliding_window_length/2),time_len-int(sliding_window_length/2)\n",
    "for v in range(var_num): \n",
    "    for i in range(covariance_num):\n",
    "        a1[v].plot(range(time_len),timecorr_correlations[v,i],c='C'+str(i),alpha=1,linestyle='-', label=\"timecorr recovery wrt ground truth \"+str(i))\n",
    "        a1[v].plot([range(time_len) for z in range(2)],[timecorr_correlations[v,i]+timecorr_correlations_std[v,i],timecorr_correlations[v,i]-timecorr_correlations_std[v,i]],c='C'+str(i),linestyle='-',alpha=0.2, label = \"timecorr recovery wrt component A\")\n",
    "        a1[v].plot(range(lower_limit,upper_limit),sliding_window_correlations[i,lower_limit:upper_limit],c='C'+str(i),alpha=0.5,linestyle='--', label=\"sliding window recovery wrt ground truth \"+str(i))    \n",
    "        a1[v].plot(range(time_len),true_correlations[i],c='C'+str(i),alpha=1,linestyle='-.')\n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[v],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "    a2[v].plot([range(time_len) for i in range(2)],[timecorr_correlations_single[v]+timecorr_correlations_single_std[v],timecorr_correlations_single[v]-timecorr_correlations_single_std[v]],c='r',linestyle='-',alpha=0.1, label = \"timecorr recovery wrt component A\")\n",
    "    a2[v].plot(range(lower_limit,upper_limit),sliding_window_correlations_single[lower_limit:upper_limit],c='C1',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "#     if v==var_num-1:\n",
    "#         a1[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a2[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a3[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "#         a4[v].legend(bbox_to_anchor=(2, 1), loc=0)\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#block 9\n",
    "\n",
    "######## timecorr vs sliding window, different variances & ramp correlation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "from _shared.helpers import wcorr, sliding_window\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "variance = 300\n",
    "sliding_window_length = [11,25,51,101]\n",
    "repetitions=100\n",
    "length_num = len(sliding_window_length)\n",
    "\n",
    "block_length = 150\n",
    "covariance_num = 2\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 5\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_ramp_correlation_data():\n",
    "    global activations, correlations,correlation1,correlation2\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "    correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "    \n",
    "    while not is_pos_def(correlation1):\n",
    "        feature_map = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation1 = 2*np.dot(feature_map,feature_map.T)-1\n",
    "        correlation1 = correlation1/np.max(abs(correlation1))\n",
    "    while not is_pos_def(correlation2):\n",
    "        feature_map1 = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation2 = 2*np.dot(feature_map1,feature_map1.T)-1\n",
    "        correlation2 = correlation2/np.max(abs(correlation2))\n",
    "#     for i in range(time_len):\n",
    "#         cov_temp = (time_len-i)*0.5*(np.log(1+correlation1+1e-5) - np.log(1-correlation1+1e-5))/float(time_len)+i*0.5*(np.log(1+correlation2+1e-5) - np.log(1-correlation2+1e-5))/float(time_len)\n",
    "#         correlations[i] =  (np.exp(2*cov_temp) - 1)/(np.exp(2*cov_temp) + 1)\n",
    "#         activations[:,i] = np.dot(cholesky(correlations[i]),activations[:,i])\n",
    "    activations[:,:block_length]=np.dot(cholesky(correlation1),activations[:,:block_length])\n",
    "    activations[:,block_length:]=np.dot(cholesky(correlation2),activations[:,block_length:])\n",
    "    \n",
    "timecorr_correlations1,timecorr_correlations2 = np.zeros([repetitions,time_len]),np.zeros([repetitions,time_len])\n",
    "sliding_window_correlations1,sliding_window_correlations2 = np.zeros([length_num,time_len]),np.zeros([length_num,time_len])\n",
    "true_correlations1,true_correlations2 = np.zeros([time_len]),np.zeros([time_len])\n",
    "\n",
    "timecorr_correlations_single = np.zeros([repetitions,time_len])\n",
    "sliding_window_correlations_single = np.zeros([length_num,time_len])\n",
    "random_correlations_single = np.zeros([time_len])\n",
    "color = ['b','r','k']\n",
    "\n",
    "#timecorr_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\n",
    "timecorr_recovery = np.zeros([var_num,time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "sliding_window_recovery = np.zeros([length_num, time_len, int((activation_num * (activation_num-1) / 2))])\n",
    "true_recovery = np.zeros([time_len,int((activation_num * (activation_num-1) / 2))])\n",
    "\n",
    "\n",
    "for i in range(repetitions):\n",
    "    cholesky_ramp_correlation_data()\n",
    "    timecorr_recovery = wcorr(activations,variance)\n",
    "    for t in range (int(time_len/2)):\n",
    "        true_recovery[t] = squareform(correlation1,checks=False)\n",
    "    for t in range(int(time_len/2),time_len):\n",
    "        true_recovery[t] = squareform(correlation2,checks=False)\n",
    "    for v in range(length_num):\n",
    "        sliding_window_recovery[v,(sliding_window_length[v]-1):] = sliding_window(activations,sliding_window_length[v])\n",
    "    \n",
    "    for timepoint in range(time_len):\n",
    "        for v in range(length_num):\n",
    "            if timepoint>int(sliding_window_length[v]/2)-1 and timepoint<time_len-int(sliding_window_length[v]/2):\n",
    "                sc1 = pearsonr(sliding_window_recovery[v,timepoint+int(sliding_window_length[v]/2)], squareform(correlation1,checks=False))[0]\n",
    "                sliding_window_correlations1[v,timepoint] += 0.5 * (log(1+sc1) - log(1-sc1))\n",
    "                sc2 = pearsonr(sliding_window_recovery[v,timepoint+int(sliding_window_length[v]/2)], squareform(correlation2,checks=False))[0]\n",
    "                sliding_window_correlations2[v,timepoint] += 0.5 * (log(1+sc2) - log(1-sc2))\n",
    "\n",
    "                swc = pearsonr(sliding_window_recovery[v,timepoint+int(sliding_window_length[v]/2)], true_recovery[timepoint])[0]\n",
    "                sliding_window_correlations_single[v,timepoint] += 0.5 * (log(1+swc) - log(1-swc))\n",
    "        \n",
    "        \n",
    "        otc1 = pearsonr(timecorr_recovery[timepoint], squareform(correlation1,checks=False))[0]\n",
    "        timecorr_correlations1[i,timepoint] += 0.5 * (log(1+otc1) - log(1-otc1))\n",
    "        otc2 = pearsonr(timecorr_recovery[timepoint], squareform(correlation2,checks=False))[0]\n",
    "        timecorr_correlations2[i,timepoint] += 0.5 * (log(1+otc2) - log(1-otc2))\n",
    "\n",
    "        otcs = pearsonr(timecorr_recovery[timepoint], true_recovery[timepoint])[0]\n",
    "        timecorr_correlations_single[i,timepoint]+= 0.5 * (log(1+otcs) - log(1-otcs))\n",
    "\n",
    "        tc1 = pearsonr(true_recovery[timepoint], squareform(correlation1,checks=False))[0]\n",
    "        true_correlations1[timepoint] += 0.5 * (log(1+tc1) - log(1-tc1+1e-5))\n",
    "        tc2 = pearsonr(true_recovery[timepoint], squareform(correlation2,checks=False))[0]\n",
    "        true_correlations2[timepoint] += 0.5 * (log(1+tc2) - log(1-tc2+1e-5))\n",
    "\n",
    "\n",
    "           \n",
    "timecorr_correlations1_std = np.std(timecorr_correlations1,0)/sqrt(repetitions)\n",
    "timecorr_correlations1_std =  (np.exp(2*timecorr_correlations1_std) - 1)/(np.exp(2*timecorr_correlations1_std) + 1)\n",
    "timecorr_correlations1 = np.mean(timecorr_correlations1,0)\n",
    "timecorr_correlations1 =  (np.exp(2*timecorr_correlations1) - 1)/(np.exp(2*timecorr_correlations1) + 1)\n",
    "\n",
    "           \n",
    "timecorr_correlations2_std = np.std(timecorr_correlations2,0)/sqrt(repetitions)\n",
    "timecorr_correlations2_std =  (np.exp(2*timecorr_correlations2_std) - 1)/(np.exp(2*timecorr_correlations2_std) + 1)\n",
    "timecorr_correlations2 = np.mean(timecorr_correlations2,0)\n",
    "timecorr_correlations2 =  (np.exp(2*timecorr_correlations2) - 1)/(np.exp(2*timecorr_correlations2) + 1)\n",
    "\n",
    "sliding_window_correlations1 /= repetitions\n",
    "sliding_window_correlations1 =  (np.exp(2*sliding_window_correlations1) - 1)/(np.exp(2*sliding_window_correlations1) + 1)\n",
    "\n",
    "sliding_window_correlations2 /= repetitions\n",
    "sliding_window_correlations2 =  (np.exp(2*sliding_window_correlations2) - 1)/(np.exp(2*sliding_window_correlations2) + 1)\n",
    "\n",
    "true_correlations1 /= repetitions\n",
    "true_correlations1 =  (np.exp(2*true_correlations1) - 1)/(np.exp(2*true_correlations1) + 1)\n",
    "\n",
    "true_correlations2 /= repetitions\n",
    "true_correlations2 =  (np.exp(2*true_correlations2) - 1)/(np.exp(2*true_correlations2) + 1)\n",
    "\n",
    "timecorr_correlations_single_std = np.std(timecorr_correlations_single,0)/sqrt(repetitions)\n",
    "timecorr_correlations_single_std =  (np.exp(2*timecorr_correlations_single_std) - 1)/(np.exp(2*timecorr_correlations_single_std) + 1)\n",
    "timecorr_correlations_single = np.mean(timecorr_correlations_single,0)\n",
    "timecorr_correlations_single = (np.exp(2*timecorr_correlations_single) - 1)/(np.exp(2*timecorr_correlations_single) + 1) \n",
    "sliding_window_correlations_single /= repetitions\n",
    "sliding_window_correlations_single =(np.exp(2*sliding_window_correlations_single) - 1)/(np.exp(2*sliding_window_correlations_single) + 1) \n",
    "\n",
    "f, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, sharey='row', figsize=(24,10))\n",
    "a1,a2 = [ax1,ax2,ax3,ax4],[ax5,ax6,ax7,ax8]\n",
    "plt.subplots_adjust(top=0.92)\n",
    "\n",
    "# plt.suptitle(\"temporal ground truth linearly transforming from component A to component B over 1000 timepoints\",fontsize=20)\n",
    "a1[0].set_title(\"variance = 300, sliding window = 11\",fontsize=18)\n",
    "a1[1].set_title(\"variance = 300, sliding window = 25\",fontsize=18)\n",
    "a1[2].set_title(\"variance = 300, sliding window = 51\",fontsize=18)\n",
    "a1[3].set_title(\"variance = 300, sliding window = 101\",fontsize=18)\n",
    "a1[0].set_ylabel(\"correlation wrt. components\",fontsize=16)\n",
    "a2[0].set_ylabel(\"correlation wrt. temporal ground truth\",fontsize=16)\n",
    "for v in range(length_num): \n",
    "    a1[v].plot(range(time_len),timecorr_correlations1[:],c=color[0],linestyle='-',alpha=1.0, label = \"timecorr recovery wrt component A\")\n",
    "    a1[v].plot(range(time_len),timecorr_correlations2[:],c=color[1],linestyle='-',alpha=1.0,label = \"timecorr recovery wrt component B\")\n",
    "    #a1[v].plot(range(sliding_window_length[v]/2,(time_len-sliding_window_length[v]/2)),sliding_window_correlations1[v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2)],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\")\n",
    "    #a1[v].plot(range(int(sliding_window_length[v]/2,(time_len-sliding_window_length[v]/2)),sliding_window_correlations1[v,int(sliding_window_length[v]/2):(int(time_len-sliding_window_length[v]/2))],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\"))\n",
    "    a1[v].plot(range(int(sliding_window_length[v]/2),int(time_len-sliding_window_length[v]/2)),sliding_window_correlations1[v,int(sliding_window_length[v]/2):int((time_len-sliding_window_length[v]/2))],c=color[0],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component A\")\n",
    "    #a1[v].plot(range(sliding_window_length[v]/2,(time_len-sliding_window_length[v]/2)),sliding_window_correlations2[v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2)],c=color[1],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component B\")\n",
    "    #a1[v].plot(range(int(sliding_window_length[v]/2,(time_len-sliding_window_length[v]/2)),sliding_window_correlations2[int(v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2))],c=color[1],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component B\"))\n",
    "    a1[v].plot(range(int(sliding_window_length[v]/2),int(time_len-sliding_window_length[v]/2)),sliding_window_correlations2[v,int(sliding_window_length[v]/2):int((time_len-sliding_window_length[v]/2))],c=color[1],linestyle='--',alpha=0.5,label = \"sliding window recovery wrt component B\")\n",
    "    a1[v].plot(range(time_len),true_correlations1[:],c=color[0],linestyle='-.',alpha=0.5,label = \"temporal ground truth wrt component A\")\n",
    "    a1[v].plot(range(time_len),true_correlations2[:],c=color[1],linestyle='-.',alpha=0.5,label = \"temporal ground truth wrt component B\")\n",
    "    a1[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a1[v].tick_params(labelsize=15)\n",
    "#     if v==length_num-1:\n",
    "#         a1[v].legend(bbox_to_anchor=(2, 1), loc=1)\n",
    "    a1[v].plot([range(time_len) for i in range(2)],[timecorr_correlations1+timecorr_correlations1_std,timecorr_correlations1-timecorr_correlations1_std],c=color[0],linestyle='-',alpha=0.3, label = \"timecorr recovery wrt component A\")\n",
    "    a1[v].plot([range(time_len) for i in range(2)],[timecorr_correlations2+timecorr_correlations2_std,timecorr_correlations2-timecorr_correlations2_std],c=color[1],linestyle='-',alpha=0.3, label = \"timecorr recovery wrt component A\")\n",
    "    a2[v].plot([range(time_len) for i in range(2)],[timecorr_correlations_single+timecorr_correlations_single_std,timecorr_correlations_single-timecorr_correlations_single_std],c='r',linestyle='-',alpha=0.3, label = \"timecorr recovery wrt component A\")\n",
    "\n",
    "    a2[v].plot(range(time_len),timecorr_correlations_single[:],c='r',alpha=1,linestyle='-', label = \"timecorr recovery wrt temporal ground truth\")\n",
    "    #a2[v].plot(range(sliding_window_length[v]/2,(time_len-sliding_window_length[v]/2)),sliding_window_correlations_single[v,sliding_window_length[v]/2:(time_len-sliding_window_length[v]/2)],c='b',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].plot(range(int(sliding_window_length[v]/2),int((time_len-sliding_window_length[v]/2))),sliding_window_correlations_single[v, int(sliding_window_length[v]/2):int((time_len-sliding_window_length[v]/2))],c='b',alpha=0.5,linestyle='--', label = \"sliding window recovery wrt temporal ground truth\")\n",
    "    a2[v].set_xlabel(\"time\",fontsize=18)\n",
    "    a2[v].tick_params(labelsize=15)\n",
    "#     if v==length_num-1:\n",
    "#         a2[v].legend(bbox_to_anchor=(2, 1), loc=1)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "#end block 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
