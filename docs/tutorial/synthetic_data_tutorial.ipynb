{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Tutorial: Exploring Dynamic Correlations\n",
    "\n",
    "This tutorial demonstrates how to generate and analyze synthetic time-series data using the timecorr toolbox. We'll explore different types of synthetic data generation methods and show how to compute dynamic correlations with various kernel functions.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dynamic correlations capture how relationships between variables change over time. The timecorr toolbox provides powerful tools for:\n",
    "- Computing moment-by-moment correlations\n",
    "- Exploring higher-order correlation structure\n",
    "- Analyzing time-varying connectivity patterns\n",
    "\n",
    "This tutorial will walk you through generating synthetic datasets with known correlation structures and analyzing them using timecorr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import timecorr\n",
    "import timecorr as tc\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Generation\n",
    "\n",
    "The timecorr toolbox provides several methods for generating synthetic datasets with different correlation structures. Let's explore each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for synthetic data generation\n",
    "T = 200  # Number of time points\n",
    "K = 10   # Number of features/variables\n",
    "B = 5    # Number of blocks (for block dataset)\n",
    "\n",
    "# Generate different types of synthetic data\n",
    "datasets = {}\n",
    "\n",
    "# 1. Random dataset - uncorrelated Gaussian noise\n",
    "datasets['random'] = tc.simulate_data(datagen='random', T=T, K=K, set_random_seed=42)\n",
    "\n",
    "# 2. Constant dataset - stable correlations over time\n",
    "datasets['constant'] = tc.simulate_data(datagen='constant', T=T, K=K, set_random_seed=42)\n",
    "\n",
    "# 3. Block dataset - correlation structure changes in blocks\n",
    "datasets['block'] = tc.simulate_data(datagen='block', T=T, K=K, B=B, set_random_seed=42)\n",
    "\n",
    "# 4. Ramping dataset - gradual changes in correlation structure\n",
    "datasets['ramping'] = tc.simulate_data(datagen='ramping', T=T, K=K, set_random_seed=42)\n",
    "\n",
    "print(\"Generated datasets:\")\n",
    "for name, data in datasets.items():\n",
    "    print(f\"{name}: shape {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing Synthetic Data\n",
    "\n",
    "Let's visualize the different types of synthetic data to understand their characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to visualize all datasets\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, data) in enumerate(datasets.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the first few features over time\n",
    "    for j in range(min(5, K)):\n",
    "        ax.plot(data[:, j], alpha=0.7, label=f'Feature {j+1}')\n",
    "    \n",
    "    ax.set_title(f'{name.title()} Dataset', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlation matrices for each dataset type\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "for i, (name, data) in enumerate(datasets.items()):\n",
    "    # Compute static correlation matrix\n",
    "    corr_matrix = np.corrcoef(data.T)\n",
    "    \n",
    "    # Plot correlation matrix\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "                vmin=-1, vmax=1, ax=axes[i])\n",
    "    axes[i].set_title(f'{name.title()} Correlations')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kernel Functions for Dynamic Correlations\n",
    "\n",
    "The timecorr toolbox provides several kernel functions that determine how much each timepoint contributes to the correlation at each moment. Let's explore the different kernel options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different kernel functions and their parameters\n",
    "T_kernel = 50  # Number of timepoints for kernel visualization\n",
    "\n",
    "kernels = {\n",
    "    'Delta (Eye)': {'func': tc.eye_weights, 'params': {}},\n",
    "    'Gaussian': {'func': tc.gaussian_weights, 'params': {'var': 100}},\n",
    "    'Laplace': {'func': tc.laplace_weights, 'params': {'scale': 10}},\n",
    "    'Mexican Hat': {'func': tc.mexican_hat_weights, 'params': {'sigma': 5}},\n",
    "    'Boxcar': {'func': tc.boxcar_weights, 'params': {'width': 20}},\n",
    "    'Uniform': {'func': tc.uniform_weights, 'params': {}}\n",
    "}\n",
    "\n",
    "# Generate and visualize kernel functions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, kernel_info) in enumerate(kernels.items()):\n",
    "    # Generate kernel weights\n",
    "    weights = kernel_info['func'](T_kernel, kernel_info['params'])\n",
    "    \n",
    "    # Plot kernel as heatmap\n",
    "    im = axes[i].imshow(weights, cmap='viridis', aspect='auto')\n",
    "    axes[i].set_title(f'{name} Kernel', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Time')\n",
    "    axes[i].set_ylabel('Time')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show kernel profiles (central timepoint)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "center_point = T_kernel // 2\n",
    "\n",
    "for name, kernel_info in kernels.items():\n",
    "    weights = kernel_info['func'](T_kernel, kernel_info['params'])\n",
    "    ax.plot(weights[center_point, :], label=name, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Time Offset')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Kernel Function Profiles', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Computing Dynamic Correlations\n",
    "\n",
    "Now let's compute dynamic correlations using different kernel functions on our synthetic datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a dataset for dynamic correlation analysis\n",
    "data = datasets['block']  # Block dataset shows clear temporal structure\n",
    "\n",
    "# Compute dynamic correlations with different kernels\n",
    "dynamic_corrs = {}\n",
    "\n",
    "# Use a subset of kernels for clarity\n",
    "selected_kernels = ['Delta (Eye)', 'Gaussian', 'Laplace', 'Mexican Hat']\n",
    "\n",
    "for kernel_name in selected_kernels:\n",
    "    kernel_info = kernels[kernel_name]\n",
    "    \n",
    "    # Compute dynamic correlations\n",
    "    dynamic_corrs[kernel_name] = tc.timecorr(\n",
    "        data, \n",
    "        weights_function=kernel_info['func'],\n",
    "        weights_params=kernel_info['params']\n",
    "    )\n",
    "    \n",
    "    print(f\"{kernel_name}: Dynamic correlations shape {dynamic_corrs[kernel_name].shape}\")\n",
    "\n",
    "print(f\"\\nOriginal data shape: {data.shape}\")\n",
    "print(f\"Dynamic correlations capture {data.shape[1]} variables over {data.shape[0]} timepoints\")\n",
    "print(f\"Output has {dynamic_corrs['Gaussian'].shape[1]} features (vectorized correlation matrices)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Dynamic Correlations\n",
    "\n",
    "Let's visualize how dynamic correlations change over time for different kernel functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vectorized correlations back to matrix format for visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, kernel_name in enumerate(selected_kernels):\n",
    "    # Convert back to matrix format\n",
    "    corr_matrices = tc.vec2mat(dynamic_corrs[kernel_name])\n",
    "    \n",
    "    # Extract correlation between features 0 and 1 over time\n",
    "    corr_01 = corr_matrices[0, 1, :]\n",
    "    \n",
    "    # Plot the dynamic correlation\n",
    "    axes[i].plot(corr_01, linewidth=2, color='blue')\n",
    "    axes[i].set_title(f'{kernel_name} Kernel\\nDynamic Correlation (Features 0-1)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Time')\n",
    "    axes[i].set_ylabel('Correlation')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].set_ylim([-1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlation matrices at different time points\n",
    "time_points = [T//4, T//2, 3*T//4]  # Three time points\n",
    "fig, axes = plt.subplots(len(time_points), len(selected_kernels), figsize=(16, 12))\n",
    "\n",
    "for i, kernel_name in enumerate(selected_kernels):\n",
    "    corr_matrices = tc.vec2mat(dynamic_corrs[kernel_name])\n",
    "    \n",
    "    for j, t in enumerate(time_points):\n",
    "        # Plot correlation matrix at time t\n",
    "        sns.heatmap(corr_matrices[:, :, t], annot=False, cmap='coolwarm', \n",
    "                    center=0, vmin=-1, vmax=1, ax=axes[j, i],\n",
    "                    cbar=True if i == len(selected_kernels)-1 else False)\n",
    "        \n",
    "        if j == 0:\n",
    "            axes[j, i].set_title(f'{kernel_name}')\n",
    "        if i == 0:\n",
    "            axes[j, i].set_ylabel(f'Time {t}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Higher-Order Correlations\n",
    "\n",
    "One of the powerful features of timecorr is the ability to compute higher-order correlations - correlations between correlations. Let's explore this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute higher-order correlations using dimensionality reduction\n",
    "data = datasets['ramping']  # Use ramping dataset for gradual changes\n",
    "\n",
    "# Level 1: Standard dynamic correlations (correlations)\n",
    "level1 = tc.timecorr(\n",
    "    data, \n",
    "    weights_function=tc.gaussian_weights,\n",
    "    weights_params={'var': 50}\n",
    ")\n",
    "\n",
    "# Level 2: Correlations between correlations\n",
    "level2 = tc.timecorr(\n",
    "    data, \n",
    "    weights_function=tc.gaussian_weights,\n",
    "    weights_params={'var': 50},\n",
    "    rfun='PCA'  # Use PCA to reduce dimensionality\n",
    ")\n",
    "\n",
    "# Level 3: Correlations between correlations between correlations\n",
    "level3 = tc.timecorr(\n",
    "    level2, \n",
    "    weights_function=tc.gaussian_weights,\n",
    "    weights_params={'var': 50},\n",
    "    rfun='PCA'\n",
    ")\n",
    "\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "print(f\"Level 1 correlations shape: {level1.shape}\")\n",
    "print(f\"Level 2 correlations shape: {level2.shape}\")\n",
    "print(f\"Level 3 correlations shape: {level3.shape}\")\n",
    "\n",
    "# Visualize higher-order correlations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot first principal component of each level\n",
    "axes[0].plot(level1[:, 0], linewidth=2, color='blue')\n",
    "axes[0].set_title('Level 1: First Correlation Component')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(level2[:, 0], linewidth=2, color='red')\n",
    "axes[1].set_title('Level 2: First Component')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(level3[:, 0], linewidth=2, color='green')\n",
    "axes[2].set_title('Level 3: First Component')\n",
    "axes[2].set_xlabel('Time')\n",
    "axes[2].set_ylabel('Value')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Subject Analysis\n",
    "\n",
    "Timecorr can also analyze data from multiple subjects/sessions. Let's demonstrate inter-subject functional connectivity (ISFC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-subject data\n",
    "n_subjects = 5\n",
    "multi_subject_data = []\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    # Generate block data with some individual differences\n",
    "    subject_data = tc.simulate_data(\n",
    "        datagen='block', \n",
    "        T=T, \n",
    "        K=K, \n",
    "        B=B, \n",
    "        set_random_seed=42 + i\n",
    "    )\n",
    "    multi_subject_data.append(subject_data)\n",
    "\n",
    "print(f\"Generated data for {n_subjects} subjects\")\n",
    "print(f\"Each subject has data shape: {multi_subject_data[0].shape}\")\n",
    "\n",
    "# Compute inter-subject functional connectivity (ISFC)\n",
    "isfc_result = tc.timecorr(\n",
    "    multi_subject_data,\n",
    "    weights_function=tc.gaussian_weights,\n",
    "    weights_params={'var': 100},\n",
    "    cfun=tc.isfc  # Inter-subject functional connectivity\n",
    ")\n",
    "\n",
    "print(f\"\\nISFC result shape: {len(isfc_result)} subjects, each with shape {isfc_result[0].shape}\")\n",
    "\n",
    "# Compute within-subject correlations for comparison\n",
    "within_subject_results = []\n",
    "for subject_data in multi_subject_data:\n",
    "    within_corr = tc.timecorr(\n",
    "        subject_data,\n",
    "        weights_function=tc.gaussian_weights,\n",
    "        weights_params={'var': 100}\n",
    "    )\n",
    "    within_subject_results.append(within_corr)\n",
    "\n",
    "# Visualize comparison between within-subject and ISFC\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot within-subject correlations\n",
    "for i, within_corr in enumerate(within_subject_results):\n",
    "    within_matrices = tc.vec2mat(within_corr)\n",
    "    corr_01 = within_matrices[0, 1, :]\n",
    "    axes[0].plot(corr_01, alpha=0.7, label=f'Subject {i+1}')\n",
    "\n",
    "axes[0].set_title('Within-Subject Correlations\\n(Features 0-1)')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Correlation')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([-1, 1])\n",
    "\n",
    "# Plot ISFC correlations\n",
    "for i, isfc_corr in enumerate(isfc_result):\n",
    "    isfc_matrices = tc.vec2mat(isfc_corr)\n",
    "    corr_01 = isfc_matrices[0, 1, :]\n",
    "    axes[1].plot(corr_01, alpha=0.7, label=f'Subject {i+1}')\n",
    "\n",
    "axes[1].set_title('Inter-Subject Functional Connectivity\\n(Features 0-1)')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Correlation')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([-1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Statistical Analysis and Significance Testing\n",
    "\n",
    "Let's perform some statistical analyses on our dynamic correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple datasets for statistical analysis\n",
    "n_datasets = 20\n",
    "correlation_timeseries = []\n",
    "\n",
    "for i in range(n_datasets):\n",
    "    # Generate block dataset\n",
    "    data = tc.simulate_data(\n",
    "        datagen='block',\n",
    "        T=T,\n",
    "        K=K,\n",
    "        B=B,\n",
    "        set_random_seed=i\n",
    "    )\n",
    "    \n",
    "    # Compute dynamic correlations\n",
    "    dynamic_corr = tc.timecorr(\n",
    "        data,\n",
    "        weights_function=tc.gaussian_weights,\n",
    "        weights_params={'var': 50}\n",
    "    )\n",
    "    \n",
    "    # Convert to matrix format and extract correlation between features 0 and 1\n",
    "    corr_matrices = tc.vec2mat(dynamic_corr)\n",
    "    corr_01 = corr_matrices[0, 1, :]\n",
    "    correlation_timeseries.append(corr_01)\n",
    "\n",
    "# Convert to numpy array for analysis\n",
    "correlation_array = np.array(correlation_timeseries)\n",
    "print(f\"Correlation array shape: {correlation_array.shape}\")\n",
    "\n",
    "# Compute statistics across datasets\n",
    "mean_correlation = np.mean(correlation_array, axis=0)\n",
    "std_correlation = np.std(correlation_array, axis=0)\n",
    "sem_correlation = stats.sem(correlation_array, axis=0)\n",
    "\n",
    "# Perform t-tests at each timepoint\n",
    "t_stats, p_values = stats.ttest_1samp(correlation_array, 0, axis=0)\n",
    "\n",
    "# Apply multiple comparisons correction (Bonferroni)\n",
    "corrected_p_values = p_values * len(p_values)\n",
    "corrected_p_values = np.minimum(corrected_p_values, 1.0)\n",
    "\n",
    "# Find significant timepoints\n",
    "significant_timepoints = corrected_p_values < 0.05\n",
    "\n",
    "# Visualize statistical results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot correlation timeseries with confidence intervals\n",
    "time_points = np.arange(T)\n",
    "axes[0].fill_between(time_points, \n",
    "                     mean_correlation - 1.96 * sem_correlation,\n",
    "                     mean_correlation + 1.96 * sem_correlation,\n",
    "                     alpha=0.3, color='blue', label='95% CI')\n",
    "axes[0].plot(time_points, mean_correlation, 'b-', linewidth=2, label='Mean Correlation')\n",
    "axes[0].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "axes[0].set_title('Dynamic Correlation with 95% Confidence Interval', fontsize=14)\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Correlation')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot p-values and significance\n",
    "axes[1].plot(time_points, -np.log10(p_values), 'r-', linewidth=2, label='Uncorrected p-values')\n",
    "axes[1].plot(time_points, -np.log10(corrected_p_values), 'g-', linewidth=2, label='Bonferroni corrected')\n",
    "axes[1].axhline(y=-np.log10(0.05), color='k', linestyle='--', alpha=0.5, label='p = 0.05')\n",
    "axes[1].fill_between(time_points, 0, -np.log10(0.05), \n",
    "                     where=significant_timepoints, alpha=0.3, color='green', label='Significant')\n",
    "axes[1].set_title('Statistical Significance Over Time', fontsize=14)\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('-log10(p-value)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of significant timepoints: {np.sum(significant_timepoints)} out of {T}\")\n",
    "print(f\"Percentage of significant timepoints: {np.sum(significant_timepoints)/T*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Best Practices\n",
    "\n",
    "This tutorial has demonstrated several key concepts in dynamic correlation analysis:\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Synthetic Data Generation**: Use different data generation methods to test your analysis pipeline\n",
    "2. **Kernel Functions**: Choose appropriate kernel functions based on your temporal resolution needs\n",
    "3. **Higher-Order Correlations**: Explore correlations between correlations for deeper insights\n",
    "4. **Multi-Subject Analysis**: Use ISFC to find shared patterns across subjects\n",
    "5. **Statistical Testing**: Always perform appropriate statistical tests and corrections\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- **Validate with synthetic data**: Always test your analysis pipeline on synthetic data with known ground truth\n",
    "- **Choose appropriate kernels**: Match your kernel function to your temporal resolution requirements\n",
    "- **Consider multiple comparison corrections**: When testing across many timepoints, use appropriate corrections\n",
    "- **Visualize your results**: Always plot your data and results to understand what's happening\n",
    "- **Cross-validate**: Use different synthetic data types to ensure robustness\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Apply these techniques to your real data\n",
    "- Explore different kernel parameters for your specific use case\n",
    "- Consider advanced techniques like weighted inter-subject functional connectivity (WISFC)\n",
    "- Investigate graph-theoretic measures for network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demonstration: comparing all synthetic data types\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, data) in enumerate(datasets.items()):\n",
    "    # Compute dynamic correlations\n",
    "    dynamic_corr = tc.timecorr(\n",
    "        data,\n",
    "        weights_function=tc.gaussian_weights,\n",
    "        weights_params={'var': 50}\n",
    "    )\n",
    "    \n",
    "    # Convert to matrix format and extract correlation between features 0 and 1\n",
    "    corr_matrices = tc.vec2mat(dynamic_corr)\n",
    "    corr_01 = corr_matrices[0, 1, :]\n",
    "    \n",
    "    # Plot dynamic correlation\n",
    "    axes[i].plot(corr_01, linewidth=2, color='blue')\n",
    "    axes[i].set_title(f'{name.title()} Dataset\\nDynamic Correlation (Features 0-1)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Time')\n",
    "    axes[i].set_ylabel('Correlation')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].set_ylim([-1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Tutorial completed! You now know how to:\")\n",
    "print(\"✓ Generate synthetic data with different correlation structures\")\n",
    "print(\"✓ Choose and apply appropriate kernel functions\")\n",
    "print(\"✓ Compute dynamic correlations and higher-order correlations\")\n",
    "print(\"✓ Analyze multi-subject data with ISFC\")\n",
    "print(\"✓ Perform statistical testing on dynamic correlations\")\n",
    "print(\"✓ Visualize and interpret your results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}