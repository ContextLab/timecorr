{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import exp, sqrt, pi\n",
    "from scipy.spatial.distance import squareform, cdist\n",
    "from multiprocessing import Pool,cpu_count\n",
    "\n",
    "def coefficient_generation(timepoint):\n",
    "    '''\n",
    "    Given the guassian array generated in the main function, this function calculates the Gaussian coefficients for each timepoint\n",
    "\n",
    "    Input:\n",
    "        timepoint: the timepoint for which the coeficients are generated\n",
    "\n",
    "    Return:\n",
    "        The sum and a tiled version of the coefficient array\n",
    "    '''\n",
    "    coefficient = gaussian_array[(time_len-1-timepoint):(2*time_len-1-timepoint)]\n",
    "    return np.tile(coefficient,[activations_len,1]), np.sum(coefficient)\n",
    "\n",
    "def isfc_helper(subj):\n",
    "    '''\n",
    "    Helper function to calculate the dynamic correlation matrix for each subject\n",
    "\n",
    "    Input:\n",
    "        subj: the index of the subjec to calculate the dynamic correlation matrix for\n",
    "\n",
    "    Return:\n",
    "        A time_len x activations_len x activations_len matrix\n",
    "    '''\n",
    "    # helper method to calculate correlation matrices at each timepoint\n",
    "    def isfc_timepoint_helper(timepoint):\n",
    "        # normalize activations, summing  over other subjects and calcualte standard deviations\n",
    "        normalized_activations = activations[subj] - np.tile(np.reshape(np.sum(np.multiply(coefficients[timepoint],activations[subj]),1),[activations_len,1]),[1,time_len])/coefficients_sum[timepoint]\n",
    "        normalized_sum_activations = activations_sum[subj] - np.tile(np.reshape(np.sum(np.multiply(coefficients[timepoint],activations_sum[subj]),1),[activations_len,1]),[1,time_len])/coefficients_sum[timepoint]\n",
    "        sigma_activations  = np.sqrt(np.sum(np.multiply(coefficients[timepoint], np.square(normalized_activations)),1)/coefficients_sum[timepoint])\n",
    "        sigma_activations_sum = np.sqrt(np.sum(np.multiply(coefficients[timepoint], np.square(normalized_sum_activations)),1)/coefficients_sum[timepoint])\n",
    "        normalized_activations = np.divide(normalized_activations,np.tile(np.reshape(sigma_activations,[activations_len,1]),[1,time_len]))\n",
    "        normalized_sum_activations = np.divide(normalized_sum_activations,np.tile(np.reshape(sigma_activations_sum,[activations_len,1]),[1,time_len]))\n",
    "\n",
    "        return np.dot(np.multiply(np.tile(coefficients[timepoint,0],[activations_len,1]),normalized_activations),normalized_sum_activations.T)/coefficients_sum[timepoint]\n",
    "\n",
    "    return np.array(map(isfc_timepoint_helper, range(time_len)))\n",
    "\n",
    "def isfc(multi_activations, var=None):\n",
    "    '''\n",
    "    Function to calculate the ISFC for a multi-subject fRMI dataset\n",
    "\n",
    "    Input:\n",
    "        multi_activations: a subject_num x voxel_num x time_len numpy matrix containing the fRMI data   of multiple subjects\n",
    "\n",
    "        var: The variance of the Gaussian distribution used to represent the influence of neighboring timepoints on calculation of correlation at the current timepoint in timecorr\n",
    "\n",
    "    Return:\n",
    "        A time_len x (voxel_num^2-voxel_num)/2 dimension matrix containing the ISFC of the input fRMI dataset\n",
    "    '''\n",
    "    # reference global variables to be used in multiprocessing helper functions\n",
    "    global coefficients, activations_sum, coefficients_sum, activations\n",
    "    global gaussian_array, time_len, subj_num, activations_len\n",
    "    # assign initial parameters\n",
    "    subj_num, activations_len, time_len = multi_activations.shape[0],multi_activations.shape[1],multi_activations.shape[2]\n",
    "    if var is None:\n",
    "        gaussian_variance = min(time_len, 1000)\n",
    "    else:\n",
    "        gaussian_variance = var\n",
    "\n",
    "    coefficients_sum = np.zeros(time_len)\n",
    "    correlations= np.zeros([subj_num, time_len,activations_len,activations_len])\n",
    "    correlations_vector = np.zeros([time_len,(activations_len * (activations_len-1) / 2)])\n",
    "    coefficients = np.zeros([time_len, activations_len,time_len])\n",
    "    gaussian_array = np.array([exp(-timepoint**2/2/gaussian_variance)/sqrt(2*pi*gaussian_variance) for timepoint in range(-time_len+1,time_len)])\n",
    "    activations = np.array(multi_activations)\n",
    "\n",
    "    # generate the gaussian coefficients\n",
    "    for timepoint in range(time_len):\n",
    "        coefficients[timepoint], coefficients_sum[timepoint] = coefficient_generation(timepoint)\n",
    "\n",
    "    # create a matrix that, for each subject, contains the sum of the data for all other subjects\n",
    "    activations_sum = (np.tile(np.sum(activations,0),[subj_num,1,1]) - activations)/(subj_num-1.0)\n",
    "\n",
    "    # calculate the correlations for each timepoint for each subject\n",
    "    p = Pool(min(cpu_count()-1,subj_num))\n",
    "    correlations = np.array(p.map(isfc_helper,range(subj_num)))\n",
    "    p.terminate()\n",
    "\n",
    "    # normalize and average the correlation matrix\n",
    "    correlations_mean = np.mean(0.5*(np.log(1e-5+1+correlations) - np.log(1e-5+1-correlations)),0)\n",
    "    correlations_mean = correlations_mean+np.swapaxes(correlations_mean,1,2)\n",
    "    correlations_mean =  (np.exp(correlations_mean) - 1)/(np.exp(correlations_mean) + 1)\n",
    "\n",
    "    # transform into reverse squareform\n",
    "    for i in range(time_len):\n",
    "        correlations_vector[i] = squareform(correlations_mean[i,:,:],checks=False)\n",
    "\n",
    "    return correlations_vector\n",
    "\n",
    "\n",
    "def wcorr_helper(timepoint):\n",
    "    '''\n",
    "    Helper function to calculate the dynamic correlation at each timepoint\n",
    "\n",
    "    Input:\n",
    "        timepoint: the timepoint at which to calculate the correlationi matrix\n",
    "\n",
    "    Ouput:\n",
    "        A activations_len x activations_len matrix containing the correlation at the input timepoint\n",
    "    '''\n",
    "    # generate coefficients\n",
    "    coefficient_tiled, coefficient_sum = coefficient_generation(timepoint)\n",
    "\n",
    "    # normalize activations and calculate standard deviations\n",
    "    normalized_activations = activations - np.tile(np.reshape(np.sum(np.multiply(coefficient_tiled,activations),1),[activations_len,1]),[1,time_len])/coefficient_sum\n",
    "    sigma  = np.sqrt(np.sum(np.multiply(coefficient_tiled, np.square(normalized_activations)),1)/coefficient_sum)\n",
    "    normalized_activations = np.divide(normalized_activations,np.tile(np.reshape(sigma,[activations_len,1]),[1,time_len]))\n",
    "\n",
    "    return squareform(np.dot(np.multiply(coefficient_tiled,normalized_activations),normalized_activations.T)/coefficient_sum, checks=False)\n",
    "\n",
    "def wcorr(single_activations, var=None):\n",
    "    '''\n",
    "    Function to calculate the ISFC for a single-subject fRMI dataset\n",
    "\n",
    "    Input:\n",
    "        single_activations: a voxel_num x time_len numpy matrix containing the fRMI data of a single subject\n",
    "\n",
    "        var: The variance of the Gaussian distribution used to represent the influence of neighboring timepoints on calculation of correlation at the current timepoint in timecorr\n",
    "\n",
    "    Return:\n",
    "        A time_len x (voxel_num^2-voxel_num)/2 dimension matrix containing the ISFC of the input fRMI dataset\n",
    "    '''\n",
    "    # reference global paramters for multiprocessing\n",
    "    global gaussian_array, activations, time_len, activations_len\n",
    "    # assign initial parameters\n",
    "    activations = single_activations\n",
    "    activations_len, time_len= activations.shape\n",
    "    if var is None:\n",
    "        gaussian_variance = min(time_len, 1000)\n",
    "    else:\n",
    "        gaussian_variance = var\n",
    "\n",
    "    # generate gaussian coefficients\n",
    "    gaussian_array = np.array([exp(-timepoint**2/2/gaussian_variance)/sqrt(2*pi*gaussian_variance) for timepoint in range(-time_len+1,time_len)])\n",
    "\n",
    "    # using multiprocessing to calculate correlations at each timepoint\n",
    "    p = Pool(cpu_count()-1)\n",
    "    correlations_vectors = np.array(p.map(wcorr_helper, range(time_len)))\n",
    "    p.terminate()\n",
    "\n",
    "    return correlations_vectors\n",
    "\n",
    "def timecorr_smoothing(single_activations, var=None):\n",
    "    global gaussian_array, activations, time_len, activations_len\n",
    "    activations = single_activations\n",
    "    activations_len, time_len= activations.shape\n",
    "    smoothed_activations = np.zeros([time_len,activations_len])\n",
    "    if var is None:\n",
    "        gaussian_variance = min(time_len, 1000)\n",
    "    else:\n",
    "        gaussian_variance = var\n",
    "    # generate gaussian coefficients\n",
    "    gaussian_array = np.array([exp(-timepoint**2/2/gaussian_variance)/sqrt(2*pi*gaussian_variance) for timepoint in range(-time_len+1,time_len)])\n",
    "    for timepoint in range(time_len):\n",
    "        coefficient_tiled, coefficient_sum = coefficient_generation(timepoint)\n",
    "        smoothed_activations[timepoint,:] = np.sum(np.multiply(coefficient_tiled,activations),1)/coefficient_sum\n",
    "\n",
    "    return smoothed_activations\n",
    "\n",
    "def sliding_window(activations, window_length):\n",
    "    '''\n",
    "    Sliding window approach to calculate dynamic correlations for single subject\n",
    "\n",
    "    Input:\n",
    "        activations: activations_len x time_len matrix containing fRMI for a single subject\n",
    "\n",
    "        window_length: length of the window to use to calculate correlation at a timepoint\n",
    "\n",
    "    Return:\n",
    "        A time_len x (voxel_num^2-voxel_num)/2 dimension matrix containing the dynamic correlations of the input fRMI dataset\n",
    "    '''\n",
    "    activations_len, time_len = activations.shape\n",
    "    time_len -= window_length-1\n",
    "    correlations = np.zeros([time_len,activations_len,activations_len])\n",
    "    correlations_vector = np.zeros([time_len,(activations_len * (activations_len-1) / 2)])\n",
    "\n",
    "    for timepoint in range(time_len):\n",
    "        correlations[timepoint] = np.corrcoef(activations[:,timepoint:(timepoint+window_length)])\n",
    "        correlations_vector[timepoint] = squareform(correlations[timepoint,:,:],checks=False)\n",
    "\n",
    "    return correlations_vector\n",
    "\n",
    "def sliding_window_smoothing(activations, window_length):\n",
    "    activations_len, time_len = activations.shape\n",
    "    time_len -= window_length-1\n",
    "    smoothed_activations = np.zeros([time_len,activations_len])\n",
    "    for timepoint in range(time_len):\n",
    "        smoothed_activations[timepoint,:] = np.mean(activations[:,timepoint:(timepoint+window_length)],1)\n",
    "\n",
    "    return smoothed_activations\n",
    "\n",
    "def sliding_window_isfc(activations, window_length):\n",
    "    '''\n",
    "    Sliding window approach to calculate dynamic correlations for multiple subjects\n",
    "\n",
    "    Input:\n",
    "        activations: subject_num x activations_len x time_len matrix containing fRMI for a multiple subjects\n",
    "\n",
    "        window_length: length of the window to use to calculate correlation at a timepoint\n",
    "\n",
    "    Return:\n",
    "        A time_len x (voxel_num^2-voxel_num)/2 dimension matrix containing the ISFC of the input fRMI dataset\n",
    "    '''\n",
    "    activations = np.array(activations)\n",
    "    subj_num, activations_len, time_len= activations.shape[0],activations.shape[1],activations.shape[2]-window_length+1\n",
    "    correlations= np.zeros([subj_num, time_len,activations_len,activations_len])\n",
    "    correlations_vector = np.zeros([time_len,(activations_len * (activations_len-1) / 2)])\n",
    "    activations = np.array(activations)\n",
    "    activations_sum = (np.tile(np.sum(activations,0),[subj_num,1,1]) - activations)/(subj_num-1.0)\n",
    "    for subj in range(subj_num):\n",
    "        for timepoint in range(time_len):\n",
    "            correlations[subj, timepoint] = 1-cdist(activations[subj,:,timepoint:(timepoint+window_length)],activations_sum[subj,:,timepoint:(timepoint+window_length)],\"correlation\")\n",
    "\n",
    "    #normalize and average the correlation matrix\n",
    "    correlations_mean = np.mean(0.5*(np.log(1e-5+1+correlations) - np.log(1e-5+1-correlations)),0)\n",
    "    correlations_mean = correlations_mean+np.swapaxes(correlations_mean,1,2)\n",
    "    correlations_mean =  (np.exp(correlations_mean) - 1)/(np.exp(correlations_mean) + 1)\n",
    "\n",
    "    for i in range(time_len):\n",
    "        correlations_vector[i] = squareform(correlations_mean[i,:,:],checks=False)\n",
    "\n",
    "    return correlations_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../timecorr/'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import numpy as np\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "block_length = 1\n",
    "covariance_num = 300\n",
    "time_len = block_length * covariance_num\n",
    "activation_num = 500\n",
    "activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "correlation1,correlation2 = np.zeros([activation_num,activation_num]), np.zeros([activation_num,activation_num])\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "def cholesky_ramp_correlation_data():\n",
    "    global activations, correlations,correlation1,correlation2\n",
    "    correlations = np.zeros([covariance_num,activation_num,activation_num])\n",
    "    activations = np.random.normal(0,10,[activation_num, time_len])\n",
    "    \n",
    "    while not is_pos_def(correlation1):\n",
    "        feature_map = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation1 = np.dot(feature_map,feature_map.T)\n",
    "        correlation1 = correlation1/np.max(abs(correlation1))\n",
    "    while not is_pos_def(correlation2):\n",
    "        feature_map1 = np.random.normal(0,1,[activation_num,activation_num])\n",
    "        correlation2 = np.dot(feature_map1,feature_map1.T)\n",
    "        correlation2 = correlation2/np.max(abs(correlation2))\n",
    "    for i in range(time_len):\n",
    "        cov_temp = (1000-i)*correlation1/float(time_len)+i*correlation2/float(time_len)\n",
    "        correlations[i] = cov_temp/np.max(abs(cov_temp))\n",
    "        activations[:, i] = np.dot(cholesky(correlations[i]),activations[:,i])\n",
    "\n",
    "\n",
    "cholesky_ramp_correlation_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c6b8e41dc763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#from _shared.helpers_temp1 import wcorr as lolol\\nfrom mnt.timecorr.timecorr._shared.helpers2 import wcorr as lolol\\nvariance = 1000\\nrepetitions=100\\ntimecorr_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\\nfor i in range(repetitions):\\n    timecorr_recovery = lolol(activations,variance)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mnt'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#from _shared.helpers_temp1 import wcorr as lolol\n",
    "from mnt.timecorr.timecorr._shared.helpers2 import wcorr as lolol\n",
    "variance = 1000\n",
    "repetitions=100\n",
    "timecorr_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\n",
    "for i in range(repetitions):\n",
    "    timecorr_recovery = lolol(activations,variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from _shared.helpers import wcorr as haha\n",
    "variance = 1000\n",
    "repetitions=1\n",
    "timecorr_recovery = np.zeros([time_len,(activation_num * (activation_num-1) / 2)])\n",
    "for i in range(repetitions):\n",
    "    timecorr_recovery = haha(activations,variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
