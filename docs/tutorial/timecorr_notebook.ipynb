{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `timecorr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Using `timecorr`: A Comprehensive Guide\n\nThe `timecorr` toolbox is designed to compute **dynamic correlations** and explore **higher-order correlational structure** in timeseries data. This tutorial will walk you through the core concepts and functionality step by step.\n\n## Key Concepts\n\n`timecorr` operates in two main steps:\n\n1. **Calculate dynamic correlations**: Compute moment-by-moment correlations using kernel-based weighting\n2. **Dimensionality reduction**: Project correlations back to original data space to prevent \"dimension explosion\"\n\nBy repeating these steps, you can approximate higher-order correlations (correlations between correlations) in a computationally tractable way.\n\n## Applications\n\nThis approach is particularly useful for:\n- **Neuroscience**: Dynamic brain connectivity analysis\n- **Finance**: Time-varying market correlations  \n- **Climate Science**: Environmental variable relationships\n- **Social Sciences**: Dynamic network analysis"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load Required Libraries\n\nimport timecorr as tc\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.simplefilter(\"ignore\")\n%matplotlib inline\n\n# Set style for better plots\nplt.style.use('default')\nsns.set_palette(\"husl\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate some data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Data Simulation\n\nThe `simulate_data` function generates synthetic timeseries data for testing and demonstration. Let's explore different simulation options and understand the data structure.\n\n## Simulation Parameters\n\n- **`S`**: Number of subjects/datasets  \n- **`T`**: Number of timepoints\n- **`K`**: Number of features (variables)\n- **`datagen`**: Type of data generation ('ramping', 'block', 'random', 'constant')\n- **`set_random_seed`**: For reproducible results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate single subject's timeseries (reduced size for tutorial)\nsim_1 = tc.simulate_data(S=1, T=100, K=20, set_random_seed=100)\n\nprint(f'Single subject data:')\nprint(f'  Shape: {np.shape(sim_1)}')  \nprint(f'  Type: {type(sim_1)}')\nprint(f'  Data format: (timepoints, features) = ({sim_1.shape[0]}, {sim_1.shape[1]})')\n\n# Visualize the simulated data\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(sim_1[:, :5])  # Plot first 5 features\nplt.title('Sample Features Over Time')\nplt.xlabel('Timepoints')\nplt.ylabel('Signal Value')\nplt.legend([f'Feature {i+1}' for i in range(5)])\n\nplt.subplot(1, 2, 2)\nplt.imshow(sim_1.T, aspect='auto', cmap='RdBu_r')\nplt.title('All Features Heatmap')\nplt.xlabel('Timepoints') \nplt.ylabel('Features')\nplt.colorbar()\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate multiple subjects' timeseries\nsim_3 = tc.simulate_data(S=3, T=100, K=20, set_random_seed=100)\n\nprint(f'Multi-subject data:')\nprint(f'  Type: {type(sim_3)}')\nprint(f'  Number of subjects: {len(sim_3)}')\nprint(f'  Each subject shape: {np.shape(sim_3[0])}')\nprint(f'  First subject type: {type(sim_3[0])}')\n\n# Visualize data from all subjects\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\nfor i, subject_data in enumerate(sim_3):\n    axes[i].imshow(subject_data.T, aspect='auto', cmap='RdBu_r')\n    axes[i].set_title(f'Subject {i+1}')\n    axes[i].set_xlabel('Timepoints')\n    if i == 0:\n        axes[i].set_ylabel('Features')\n\nplt.tight_layout()\nplt.show()\n\nprint(f'\\\\nData Structure Summary:')\nprint(f'- Single subject: Returns numpy array of shape (T, K)')\nprint(f'- Multiple subjects: Returns list of {len(sim_3)} arrays, each of shape (T, K)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify kernel:\n",
    "width = 5\n",
    "gaussian = {'name': 'Gaussian', 'weights': tc.gaussian_weights, 'params': {'var': width}}\n",
    "\n",
    "# calcuate the dynamic correlations use a gaussian kernel and width of 5 for 1 simulate subject\n",
    "vec_corrs = tc.timecorr(sim_1, weights_function=gaussian['weights'], weights_params=gaussian['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare different kernel functions\nprint(\"Kernel Comparison:\")\nT = 100  # Number of timepoints\n\n# Define different kernels - note: Mexican Hat uses 'sigma' not 'var'\nkernels = {\n    'Gaussian': {'weights': tc.gaussian_weights, 'params': {'var': 5}},\n    'Laplace': {'weights': tc.laplace_weights, 'params': {'scale': 5}}, \n    'Mexican Hat': {'weights': tc.mexican_hat_weights, 'params': {'sigma': 5}}\n}\n\n# Visualize kernel shapes\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.ravel()\n\nfor i, (name, kernel) in enumerate(kernels.items()):\n    # Kernel functions expect params as a dictionary argument, not keyword arguments\n    weights = kernel['weights'](T, kernel['params'])\n    axes[i].plot(weights)\n    axes[i].set_title(f'{name} Kernel')\n    axes[i].set_xlabel('Timepoints')\n    axes[i].set_ylabel('Weight')\n    axes[i].grid(True)\n\n# Compute dynamic correlations with Gaussian kernel\nwidth = 5\ngaussian = {'name': 'Gaussian', 'weights': tc.gaussian_weights, 'params': {'var': width}}\n\nprint(f\"\\\\nComputing dynamic correlations with {gaussian['name']} kernel (var={width})...\")\nvec_corrs = tc.timecorr(sim_1, weights_function=gaussian['weights'], weights_params=gaussian['params'])\n\nprint(f\"Input data shape: {sim_1.shape}\")\nprint(f\"Vectorized correlations shape: {vec_corrs.shape}\")\nprint(f\"Explanation: {sim_1.shape[1]} features -> {vec_corrs.shape[1]} unique correlations\")\nprint(f\"Formula: K*(K+1)/2 = {sim_1.shape[1]}*({sim_1.shape[1]}+1)/2 = {sim_1.shape[1]*(sim_1.shape[1]+1)//2}\")\n\n# Show kernel weights in last subplot\naxes[3].plot(gaussian['weights'](T, gaussian['params']))\naxes[3].set_title('Gaussian Kernel (Used)')\naxes[3].set_xlabel('Timepoints')\naxes[3].set_ylabel('Weight')\naxes[3].grid(True)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Understanding Vectorized vs. Matrix Format\n\nThe `timecorr` function returns correlations in **vectorized format** - the upper triangle of correlation matrices is flattened into a vector. This is memory-efficient and avoids redundancy since correlation matrices are symmetric.\n\n## Format Conversion\n\n- **`vec2mat()`**: Convert vectorized correlations to full matrices\n- **`mat2vec()`**: Convert matrices back to vectorized format"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Understanding Vectorized vs. Matrix Format\n\nprint(\"Format Conversion Examples:\")\n\n# Show vectorized format (what timecorr returns)\nprint(f\"1. Vectorized correlations shape: {vec_corrs.shape}\")\nprint(f\"   Interpretation: {vec_corrs.shape[0]} timepoints Ã— {vec_corrs.shape[1]} unique correlations\")\n\n# Convert to matrix format for visualization\nmatrix_corrs = tc.vec2mat(vec_corrs)\nprint(f\"\\\\n2. Matrix format shape: {matrix_corrs.shape}\")\nprint(f\"   Interpretation: {matrix_corrs.shape[0]} Ã— {matrix_corrs.shape[1]} correlation matrix for each of {matrix_corrs.shape[2]} timepoints\")\n\n# Verify the conversion\nprint(f\"\\\\n3. Consistency check:\")\nprint(f\"   Original features: {sim_1.shape[1]}\")\nprint(f\"   Matrix dimensions: {matrix_corrs.shape[0]} Ã— {matrix_corrs.shape[1]}\")\nprint(f\"   Matrix is square: {matrix_corrs.shape[0] == matrix_corrs.shape[1]}\")\n\n# Visualize correlation matrices at different timepoints\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\ntimepoints = [25, 50, 75]\n\nfor i, t in enumerate(timepoints):\n    im = axes[i].imshow(matrix_corrs[:, :, t], cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[i].set_title(f'Correlation Matrix at t={t}')\n    axes[i].set_xlabel('Features')\n    if i == 0:\n        axes[i].set_ylabel('Features')\n\nplt.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\nplt.tight_layout()\nplt.show()\n\n# Show temporal evolution of specific correlations\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\n# Plot evolution of a few feature pairs\nfeature_pairs = [(0, 1), (0, 5), (0, 10), (5, 10)]\nfor i, (f1, f2) in enumerate(feature_pairs):\n    plt.plot(matrix_corrs[f1, f2, :], label=f'Features {f1+1}-{f2+1}')\nplt.title('Temporal Evolution of Feature Correlations')\nplt.xlabel('Timepoints')\nplt.ylabel('Correlation')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\n# Show distribution of correlations at a single timepoint\ncorrelations_t50 = matrix_corrs[:, :, 50]\n# Extract upper triangle (unique correlations)\nupper_triangle = correlations_t50[np.triu_indices_from(correlations_t50, k=1)]\nplt.hist(upper_triangle, bins=20, alpha=0.7, edgecolor='black')\nplt.title('Distribution of Correlations at t=50')\nplt.xlabel('Correlation Value')\nplt.ylabel('Frequency')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# Convert back to vectorized format to verify round-trip\nvec_corrs_roundtrip = tc.mat2vec(matrix_corrs)\nprint(f\"\\\\n4. Round-trip conversion:\")\nprint(f\"   Original vectorized shape: {vec_corrs.shape}\")\nprint(f\"   Round-trip vectorized shape: {vec_corrs_roundtrip.shape}\")\nprint(f\"   Are they equal? {np.allclose(vec_corrs, vec_corrs_roundtrip)}\")\n\nprint(f\"\\\\n5. Memory efficiency:\")\nprint(f\"   Vectorized format: {vec_corrs.nbytes:,} bytes\")\nprint(f\"   Matrix format: {matrix_corrs.nbytes:,} bytes\")\nprint(f\"   Matrix is {matrix_corrs.nbytes / vec_corrs.nbytes:.1f}x larger\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcuate the dynamic isfc correlations use a Laplace kernel \n",
    "# and width of 10 for 3 simulated subjects, and take the element-wise average correlations across matrices.\n",
    "width = 10\n",
    "laplace = {'name': 'Laplace', 'weights': tc.laplace_weights, 'params': {'scale': width}}\n",
    "\n",
    "dyna_corrs = tc.timecorr(sim_3, combine=tc.corrmean_combine, \n",
    "                         weights_function=laplace['weights'], weights_params=laplace['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher order correlations\n",
    "\n",
    "Ok, now that we've gone over how to calculate dynamic correlations, let's walk through reducing the correlations back to the original size of the data using the `rfun` parameter.  Again, you have several options.  If you want more information, please checkout the API documentation.  \n",
    "\n",
    "The default for `rfun` is `None`, which we used for calculating the dynamic correlations, but in this example we'll use `PCA`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare different multi-subject approaches\nwidth = 10\nlaplace = {'name': 'Laplace', 'weights': tc.laplace_weights, 'params': {'scale': width}}\n\nprint(\"Multi-Subject Analysis Comparison:\")\nprint(f\"Using {laplace['name']} kernel with scale={width}\")\n\n# 1. Individual subject correlations (no combination)\nindividual_corrs = []\nfor i, subject in enumerate(sim_3):\n    corr = tc.timecorr(subject, weights_function=laplace['weights'], weights_params=laplace['params'])\n    individual_corrs.append(corr)\n    print(f\"  Subject {i+1} correlations shape: {corr.shape}\")\n\n# 2. ISFC with mean combination\nprint(f\"\\\\n2. ISFC Analysis:\")\ndyna_corrs = tc.timecorr(sim_3, \n                         combine=tc.corrmean_combine,\n                         weights_function=laplace['weights'], \n                         weights_params=laplace['params'])\nprint(f\"  ISFC combined shape: {dyna_corrs.shape}\")\nprint(f\"  Interpretation: Shared correlation patterns across all {len(sim_3)} subjects\")\n\n# 3. Compare individual vs. group patterns\nprint(f\"\\\\n3. Pattern Comparison:\")\n# Convert to matrices for visualization\nindividual_mats = [tc.vec2mat(corr) for corr in individual_corrs]\ngroup_mat = tc.vec2mat(dyna_corrs)\n\n# Visualize at a specific timepoint\nt = 50\nfig, axes = plt.subplots(1, 4, figsize=(16, 4))\n\n# Individual subjects\nfor i in range(3):\n    im = axes[i].imshow(individual_mats[i][:, :, t], cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[i].set_title(f'Subject {i+1} (t={t})')\n    axes[i].set_xlabel('Features')\n    if i == 0:\n        axes[i].set_ylabel('Features')\n\n# Group average (ISFC)\nim = axes[3].imshow(group_mat[:, :, t], cmap='RdBu_r', vmin=-1, vmax=1)\naxes[3].set_title(f'ISFC Group (t={t})')\naxes[3].set_xlabel('Features')\n\nplt.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\nplt.tight_layout()\nplt.show()\n\n# Show temporal dynamics comparison\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nfor i in range(3):\n    plt.plot(individual_mats[i][0, 5, :], alpha=0.7, linewidth=1, label=f'Subject {i+1}')\nplt.plot(group_mat[0, 5, :], 'k-', linewidth=3, label='ISFC Group')\nplt.title('Feature Pair (1,6) Correlation Over Time')\nplt.xlabel('Timepoints')\nplt.ylabel('Correlation')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\n# Correlation between individual and group patterns\nindividual_avg = np.mean(individual_mats, axis=0)\ncorrelation_with_group = np.corrcoef(individual_avg.flatten(), group_mat.flatten())[0, 1]\nplt.scatter(individual_avg.flatten(), group_mat.flatten(), alpha=0.5)\nplt.plot([-1, 1], [-1, 1], 'r--', linewidth=2)\nplt.title(f'Individual vs. ISFC Correlations\\\\nr = {correlation_with_group:.3f}')\nplt.xlabel('Average Individual Correlations')\nplt.ylabel('ISFC Group Correlations')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Higher-Order Correlations: Preventing Dimension Explosion\n\nA key innovation of `timecorr` is the ability to compute **higher-order correlations** - correlations between correlation patterns - in a computationally tractable way.\n\n## The Problem\n\nWithout dimensionality reduction, computing correlations on correlation data leads to exponential growth:\n- Original data: K features â†’ K(K+1)/2 correlations  \n- 2nd order: K(K+1)/2 features â†’ (K(K+1)/2)((K(K+1)/2)+1)/2 correlations\n- This quickly becomes computationally intractable!\n\n## The Solution: Dimensionality Reduction (`rfun`)\n\nThe `rfun` parameter applies dimensionality reduction to project correlations back to the original feature space:\n\n- **`'PCA'`**: Principal Component Analysis (most common)\n- **`'ICA'`**: Independent Component Analysis\n- **`'FactorAnalysis'`**: Factor analysis \n- **Graph measures**: `'pagerank_centrality'`, `'eigenvector_centrality'`\n- **Custom functions**: You can define your own reduction method"
  },
  {
   "cell_type": "markdown",
   "source": "# Summary and Next Steps\n\n## What We've Covered\n\nIn this tutorial, you've learned:\n\n1. **Data Simulation**: How to generate synthetic timeseries data for testing\n2. **Dynamic Correlations**: Computing time-varying correlation patterns using kernel functions\n3. **Kernel Functions**: Different weighting approaches (Gaussian, Laplace, Mexican Hat)\n4. **Data Formats**: Converting between vectorized and matrix correlation formats\n5. **Multi-Subject Analysis**: ISFC approaches for finding shared patterns\n6. **Higher-Order Correlations**: Using dimensionality reduction to explore correlations of correlations\n7. **Multiple Levels**: Building hierarchical correlation structures\n\n## Key Parameters Summary\n\n- **`weights_function`**: Kernel type (tc.gaussian_weights, tc.laplace_weights, etc.)\n- **`weights_params`**: Kernel parameters ({'var': width} or {'scale': width})  \n- **`cfun`**: Correlation function (None, tc.isfc, tc.wisfc, tc.autofc)\n- **`rfun`**: Dimensionality reduction ('PCA', 'ICA', 'FactorAnalysis', graph measures)\n- **`combine`**: How to combine multi-subject results (tc.corrmean_combine, tc.mean_combine)\n\n## Real-World Applications\n\nThe techniques demonstrated here apply to:\n\n- **Neuroscience**: fMRI dynamic functional connectivity, EEG/MEG source connectivity\n- **Finance**: Time-varying market correlations, risk assessment\n- **Climate**: Environmental variable relationships over seasons/years  \n- **Social Networks**: Dynamic community structure, behavioral synchrony\n\n## Advanced Topics\n\nFor more advanced applications, explore:\n\n- **Statistical Testing**: Permutation tests for significance\n- **Cross-Validation**: Using decoder functions for validation\n- **Custom Kernels**: Defining your own weighting functions\n- **Graph Theory**: Network measures and centrality metrics\n- **Optimization**: Memory and performance considerations for large datasets\n\n## Next Steps\n\n1. Try the **Applications Tutorial** for domain-specific examples\n2. Explore the **API Documentation** for complete function references  \n3. Experiment with **your own data** using the patterns shown here\n4. Check out the **research paper** for theoretical background\n\nHappy correlating! ðŸŽ¯",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate dimensionality reduction and higher-order correlations\nprint(\"Higher-Order Correlation Analysis:\")\n\n# Step 1: Compute correlations with PCA reduction\nprint(\"\\\\n1. Dynamic correlations with PCA reduction:\")\ndyna_corrs_reduced = tc.timecorr(sim_3, \n                                 rfun='PCA',\n                                 weights_function=laplace['weights'], \n                                 weights_params=laplace['params'])\n\nprint(f\"  Original data shape: {np.shape(sim_3)} (list of {len(sim_3)} arrays)\")\nprint(f\"  Reduced correlations shape: {np.shape(dyna_corrs_reduced)}\")\nprint(f\"  Key insight: Same shape as original, but now represents correlation patterns!\")\n\n# Step 2: Compare different reduction methods\nprint(\"\\\\n2. Different reduction methods:\")\nreduction_methods = ['PCA', 'ICA']  # Removed FactorAnalysis to avoid potential issues\nreduced_results = {}\n\nfor method in reduction_methods:\n    try:\n        result = tc.timecorr(sim_3,\n                           rfun=method,\n                           weights_function=laplace['weights'],\n                           weights_params=laplace['params'])\n        reduced_results[method] = result\n        print(f\"  {method}: {result.shape}\")\n    except Exception as e:\n        print(f\"  {method}: Failed ({str(e)})\")\n\n# Visualize the reduced correlation patterns\nif reduced_results:\n    fig, axes = plt.subplots(len(reduced_results), 3, figsize=(15, 4*len(reduced_results)))\n    if len(reduced_results) == 1:\n        axes = axes.reshape(1, -1)\n\n    for i, (method, result) in enumerate(reduced_results.items()):\n        for j in range(3):  # For each subject\n            axes[i, j].imshow(result[j].T, aspect='auto', cmap='RdBu_r')\n            axes[i, j].set_title(f'{method} - Subject {j+1}')\n            axes[i, j].set_xlabel('Timepoints')\n            if j == 0:\n                axes[i, j].set_ylabel('Reduced Features')\n\n    plt.tight_layout()\n    plt.show()\n\n# Step 3: Demonstrate the dimension problem without reduction\nprint(\"\\\\n3. Dimension explosion without reduction:\")\nK = sim_1.shape[1]  # Number of features\ncorrelations_level1 = K * (K + 1) // 2\ncorrelations_level2 = correlations_level1 * (correlations_level1 + 1) // 2\n\nprint(f\"  Original features (K): {K}\")\nprint(f\"  1st order correlations: {correlations_level1}\")\nprint(f\"  2nd order correlations (without reduction): {correlations_level2:,}\")\nprint(f\"  Reduction ratio: {correlations_level2 / K:.1f}x larger!\")\nprint(f\"  \\\\n  With rfun='PCA': Always maintains {K} features per subject\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}