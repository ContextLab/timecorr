{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Optimized weights by level for decoding\n\nIn this example, we load in some example data, and find optimal level weights for decoding.\n\nNOTE: This example currently has compatibility issues with the weighted_timepoint_decoder function.\nFor a working example, please see the enhanced version in docs/auto_examples/decode_by_weighted_level.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Code source: Lucy Owen\n# License: MIT\n\nimport hypertools as hyp\nimport numpy as np\n\n# load timecorr and other packages\nimport timecorr as tc\n\nprint(\"Weighted Timepoint Decoding Example\")\nprint(\"=\" * 40)\nprint(\"NOTE: This example currently has compatibility issues.\")\nprint(\n    \"Please see docs/auto_examples/decode_by_weighted_level.py for a working version.\"\n)\nprint(\"=\" * 40)\n\n# load example data\ndata = hyp.load(\"weights\").get_data()\n\n# Convert to numpy array format required by weighted_timepoint_decoder\ndata_array = np.array(data)\nprint(f\"Data shape: {data_array.shape} (subjects, timepoints, features)\")\n\n# define your weights parameters\nwidth = 10\nlaplace = {\"name\": \"Laplace\", \"weights\": tc.laplace_weights, \"params\": {\"scale\": width}}\n\n# set your number of levels\n# if integer, returns decoding accuracy, error, and rank for specified level\nlevel = 2\n\nprint(f\"\\nAttempting weighted timepoint decoding at level {level}...\")\n\ntry:\n    # run timecorr with specified functions for calculating correlations, as well as combining and reducing\n    results = tc.weighted_timepoint_decoder(\n        data_array,\n        level=level,\n        combine=tc.corrmean_combine,\n        cfun=tc.isfc,\n        rfun=\"eigenvector_centrality\",\n        weights_fun=laplace[\"weights\"],\n        weights_params=laplace[\"params\"],\n    )\n\n    # returns optimal weighting for mu for all levels up to 2 as well as decoding results for each fold\n    print(\"\u2713 SUCCESS: Weighted decoding results:\")\n    print(results)\n\nexcept Exception as e:\n    print(f\"\u2717 ERROR: {e}\")\n    print(\"This function has compatibility issues with the current version.\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\n    \"RECOMMENDATION: Use the enhanced version in docs/auto_examples/decode_by_weighted_level.py\"\n)\nprint(\"which uses synthetic data and includes comprehensive error handling.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}